import os
import sys
import csv
import logging
import random
import re
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional

from playwright.sync_api import sync_playwright
from dotenv import load_dotenv

import argparse
from datetime import datetime
import pandas as pd

load_dotenv()

sys.path.append(str(Path(__file__).resolve().parent.parent.parent))
from data_pipeline.utils.slack_utils import SlackNotifier


# =========================
# Config
# =========================
@dataclass
class Config:
    url: str = "https://www.foodsafetykorea.go.kr/portal/specialinfo/searchInfoCompany.do"
    headless: bool = True
    retries: int = 1
    retry_sleep_sec: int = 5
    timeout_ms: int = 30_000
    project_root: str = "data/bronze/restaurant_owner"
    slack_webhook_url: Optional[str] = os.getenv("SLACK_WEBHOOK_URL")

    page_delay_min: float = 3.0
    page_delay_max: float = 6.0
    long_break_interval: int = 15   
    long_break_min: float = 15.0
    long_break_max: float = 25.0
    session_rotate_interval: int = 50  
    mouse_sim_probability: float = 0.6
    scroll_sim_probability: float = 0.5

    sido_mapping: dict = field(default_factory=lambda: {
        "ì„œìš¸íŠ¹ë³„ì‹œ": "ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°ê´‘ì—­ì‹œ": "ë¶€ì‚°ê´‘ì—­ì‹œ", "ëŒ€êµ¬ê´‘ì—­ì‹œ": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
        "ì¸ì²œê´‘ì—­ì‹œ": "ì¸ì²œê´‘ì—­ì‹œ", "ê´‘ì£¼ê´‘ì—­ì‹œ": "ê´‘ì£¼ê´‘ì—­ì‹œ", "ëŒ€ì „ê´‘ì—­ì‹œ": "ëŒ€ì „ê´‘ì—­ì‹œ",
        "ìš¸ì‚°ê´‘ì—­ì‹œ": "ìš¸ì‚°ê´‘ì—­ì‹œ", "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ", "ê²½ê¸°ë„": "ê²½ê¸°ë„",
        "ê°•ì›ë„": "ê°•ì›íŠ¹ë³„ìì¹˜ë„", "ì¶©ì²­ë¶ë„": "ì¶©ì²­ë¶ë„", "ì¶©ì²­ë‚¨ë„": "ì¶©ì²­ë‚¨ë„",
        "ì „ë¼ë¶ë„": "ì „ë¶íŠ¹ë³„ìì¹˜ë„", "ì „ë¼ë‚¨ë„": "ì „ë¼ë‚¨ë„", "ê²½ìƒë¶ë„": "ê²½ìƒë¶ë„",
        "ê²½ìƒë‚¨ë„": "ê²½ìƒë‚¨ë„", "ì œì£¼íŠ¹ë³„ìì¹˜ë„": "ì œì£¼íŠ¹ë³„ìì¹˜ë„",
    })


# =========================
# Logger
# =========================
def build_logger(log_file: Path) -> logging.Logger:
    logger = logging.getLogger("food_safety_search")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    fmt = logging.Formatter("%(asctime)s | %(levelname)s | %(message)s", "%Y-%m-%d %H:%M:%S")
    sh = logging.StreamHandler(sys.stdout)
    sh.setFormatter(fmt)
    fh = logging.FileHandler(log_file, encoding="utf-8")
    fh.setFormatter(fmt)
    logger.addHandler(sh)
    logger.addHandler(fh)
    return logger


# =========================
# Anti-Ban Helpers
# =========================
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_4_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_4) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3.1 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:125.0) Gecko/20100101 Firefox/125.0",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/122.0.0.0",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0",
]

VIEWPORTS = [
    {"width": 1920, "height": 1080}, {"width": 1366, "height": 768},
    {"width": 1536, "height": 864},  {"width": 1440, "height": 900},
    {"width": 1280, "height": 720},  {"width": 1600, "height": 900},
]

REFERERS = [
    "https://www.google.com/",
    "https://search.naver.com/",
    "https://www.daum.net/",
    "https://www.foodsafetykorea.go.kr/portal/main.do",
    "",
]


def _random_delay(min_sec: float = 1.0, max_sec: float = 3.0) -> None:
    time.sleep(random.uniform(min_sec, max_sec))


def _human_like_delay() -> None:
    time.sleep(random.uniform(0.3, 1.5))


def _simulate_mouse_movement(page) -> None:
    for _ in range(random.randint(2, 5)):
        x = random.randint(100, 1200)
        y = random.randint(100, 700)
        page.mouse.move(x, y, steps=random.randint(3, 10)) 
        time.sleep(random.uniform(0.05, 0.2))


def _simulate_scroll(page) -> None:
    scroll_amount = random.randint(100, 500)
    direction = random.choice([1, -1])
    page.mouse.wheel(0, scroll_amount * direction)
    time.sleep(random.uniform(0.3, 0.8))


def _simulate_human_behavior(page, cfg: Config) -> None:
    if random.random() < cfg.mouse_sim_probability:
        _simulate_mouse_movement(page)
    if random.random() < cfg.scroll_sim_probability:
        _simulate_scroll(page)
    _human_like_delay()


def _create_context(browser, logger: logging.Logger):
    ua = random.choice(USER_AGENTS)
    vp = random.choice(VIEWPORTS)
    referer = random.choice(REFERERS)

    extra_headers = {
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "Accept-Encoding": "gzip, deflate, br",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "DNT": "1",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "same-origin",
        "Sec-Fetch-User": "?1",
    }
    if referer:
        extra_headers["Referer"] = referer

    context = browser.new_context(
        user_agent=ua,
        viewport=vp,
        locale=random.choice(["ko-KR", "ko"]),
        timezone_id="Asia/Seoul",
        extra_http_headers=extra_headers,
        java_script_enabled=True,
    )

    # WebDriver ì†ì„± ìˆ¨ê¸°ê¸°
    context.add_init_script("""
        Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
        window.chrome = { runtime: {} };
        const originalQuery = window.navigator.permissions.query;
        window.navigator.permissions.query = (parameters) =>
            parameters.name === 'notifications'
                ? Promise.resolve({ state: Notification.permission })
                : originalQuery(parameters);
        Object.defineProperty(navigator, 'plugins', {
            get: () => [1, 2, 3, 4, 5],
        });
        Object.defineProperty(navigator, 'languages', {
            get: () => ['ko-KR', 'ko', 'en-US', 'en'],
        });
    """)

    page = context.new_page()
    logger.debug(f"í¬ë¡¤ë§ ì»¨í…ìŠ¤íŠ¸ ìƒì„± | UA: {ua[:50]}... | VP: {vp}")
    return context, page


# [NEW] íŠ¹ì • í˜ì´ì§€ë¡œ ì§ì ‘ ì´ë™
def _navigate_to_page(page, target_page: int, logger: logging.Logger) -> None:
    logger.info(f"ğŸ“„ {target_page} í˜ì´ì§€ë¡œ ì´ë™ ì¤‘...")
    page.evaluate(f"$('.pagination').pagination('selectPage', {target_page})")
    page.wait_for_load_state("networkidle")
    _random_delay(4.0, 6.0)


# =========================
# [NEW] ì§„í–‰ ìƒíƒœ ì €ì¥/ë³µì›
# =========================
def _save_progress(progress_file: Path, last_page: int) -> None:
    progress_file.write_text(str(last_page), encoding="utf-8")


def _load_progress(progress_file: Path) -> int:
    if progress_file.exists():
        try:
            return int(progress_file.read_text(encoding="utf-8").strip())
        except ValueError:
            return 0
    return 0


# =========================
# Main Crawler Logic
# =========================
def search_and_save_all_pages(
    sido_name: str,
    address: str,
    cfg: Config,
    logger: logging.Logger,
    output_file: Path,
    start_page: int = 1,                   
    end_page: Optional[int] = None,          
    progress_file: Optional[Path] = None,    
) -> bool:
    notifier = SlackNotifier(cfg.slack_webhook_url, "EXTRACT-ì‹ë‹¹ëŒ€í‘œì", logger)

    if sido_name not in cfg.sido_mapping:
        logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œë„ëª…: {sido_name}")
        return

    checkbox_label = cfg.sido_mapping[sido_name]
    HEADERS = ["ë²ˆí˜¸", "ì¸í—ˆê°€ë²ˆí˜¸", "ì—…ì²´ëª…", "ì—…ì¢…", "ëŒ€í‘œì", "ì†Œì¬ì§€", "ì¸í—ˆê°€ê¸°ê´€", "ì˜ì—…ìƒíƒœ", "ë¹„ê³ "]

    # ì§„í–‰ ìƒíƒœ ê¸°ë¡ íŒŒì¼ì—ì„œ ì‹œì‘ í˜ì´ì§€ ê²°ì •
    if progress_file:
        saved_page = _load_progress(progress_file)
        if saved_page > 0 and saved_page >= start_page:
            logger.info(f"ğŸ”„ ì´ì „ ì§„í–‰ ìƒíƒœ ë°œê²¬: {saved_page}í˜ì´ì§€ê¹Œì§€ ì™„ë£Œ. {saved_page + 1}í˜ì´ì§€ë¶€í„° ì¬ê°œí•©ë‹ˆë‹¤.")
            start_page = saved_page + 1

    try:
        notifier.info("ì‘ì—… ì‹œì‘", f"ëŒ€ìƒ: {sido_name} {address} (í˜ì´ì§€ {start_page}~{end_page or 'ë'})")

        with sync_playwright() as p:
            browser = p.chromium.launch(headless=cfg.headless)
            context, page = _create_context(browser, logger)

            # ê²€ìƒ‰ ì¡°ê±´ ì„¤ì • (ì„¸ì…˜ ê°±ì‹  ì‹œì—ë„ ì¬ì‚¬ìš©)
            def _setup_search(pg):
                logger.info(f"ğŸŒ í˜ì´ì§€ ì ‘ì† ì¤‘: {cfg.url}")
                pg.goto(cfg.url, timeout=cfg.timeout_ms)
                pg.wait_for_load_state("networkidle")
                _random_delay(3.0, 5.0)

                _simulate_human_behavior(pg, cfg)  #

                pg.locator('.dsL li[val="rstrt"] a').click()
                _human_like_delay()  
                pg.locator(f'input[type="checkbox"][title="{checkbox_label}"]').first.check()
                _human_like_delay()  

                addr_input = pg.locator('input[name="site_addr"]').first
                addr_input.click()
                _human_like_delay()
                for char in address:
                    addr_input.type(char, delay=random.randint(50, 180))

                _simulate_human_behavior(pg, cfg) 

                pg.locator("#srchBtn").click()
                pg.wait_for_load_state("networkidle")
                _random_delay(5.0, 8.0)

                first_row = pg.locator("#tbl_bsn_list tbody tr").first
                if first_row.count() == 0 or "ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤" in first_row.text_content():
                    return 0

                _human_like_delay()
                pg.locator("#a_list_cnt").click()
                _human_like_delay()
                pg.locator('a[val="50"]').click()
                pg.wait_for_load_state("networkidle")
                _random_delay(4.0, 6.0)

                return pg.evaluate("$('.pagination').pagination('getPagesCount')")

            total_pages = _setup_search(page)
            if total_pages == 0:
                logger.warning(f"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: {address}")
                notifier.error("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ", f"{sido_name} {address} ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                browser.close()
                return False

            # end_page ê²°ì •
            actual_end = min(end_page, total_pages) if end_page else total_pages
            if start_page > actual_end:
                logger.info(f"âœ… ì´ë¯¸ ëª¨ë“  í˜ì´ì§€ ì™„ë£Œ (ì‹œì‘={start_page}, ë={actual_end})")
                browser.close()
                return True

            logger.info(f"ì´ {total_pages} í˜ì´ì§€ ì¤‘ {start_page}~{actual_end} í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘")

            # ì‹œì‘ í˜ì´ì§€ë¡œ ì´ë™
            if start_page > 1:
                _navigate_to_page(page, start_page, logger)

            # íŒŒì¼ ëª¨ë“œ ê²°ì •
            file_mode = "w" if start_page == 1 else "a"
            write_header = (start_page == 1) or (not output_file.exists())

            with open(output_file, file_mode, encoding="utf-8", newline="") as f:
                writer = csv.writer(f)
                if write_header:
                    writer.writerow(HEADERS)

                consecutive_errors = 0      
                max_consecutive_errors = 3   

                for page_num in range(start_page, actual_end + 1):
                    try:
                        pages_done = page_num - start_page

                        # ì„¸ì…˜ ê°±ì‹  (Ní˜ì´ì§€ë§ˆë‹¤)
                        if pages_done > 0 and pages_done % cfg.session_rotate_interval == 0:
                            logger.info(f"ğŸ”„ ì„¸ì…˜ ê°±ì‹  ì¤‘ ({pages_done}í˜ì´ì§€ ì™„ë£Œ)...")
                            context.close()
                            _random_delay(10.0, 20.0)
                            context, page = _create_context(browser, logger)
                            total_pages = _setup_search(page)
                            if total_pages == 0:
                                logger.error("ì„¸ì…˜ ê°±ì‹  í›„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                                break
                            _navigate_to_page(page, page_num, logger)
                            logger.info(f"âœ… ì„¸ì…˜ ê°±ì‹  ì™„ë£Œ. {page_num}í˜ì´ì§€ë¶€í„° ê³„ì†í•©ë‹ˆë‹¤.")

                        elif page_num > start_page:
                            _simulate_human_behavior(page, cfg)  # 
                            page.locator('.pagination li:last-child a').click()
                            page.wait_for_load_state("networkidle")
                            _random_delay(cfg.page_delay_min, cfg.page_delay_max)

                        _simulate_human_behavior(page, cfg)  # 

                        # ë°ì´í„° ì¶”ì¶œ
                        rows = page.locator("#tbl_bsn_list tbody tr")
                        row_count = rows.count()

                        # ë¹ˆ ê²°ê³¼ â†’ ë°´ ì˜ì‹¬
                        if row_count == 0:
                            logger.warning(f"âš ï¸ {page_num}í˜ì´ì§€ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë°´ ê°€ëŠ¥ì„± í™•ì¸ í•„ìš”.")
                            consecutive_errors += 1
                            if consecutive_errors >= max_consecutive_errors:
                                logger.error(f"ğŸš¨ ì—°ì† {max_consecutive_errors}íšŒ ë¹ˆ ê²°ê³¼ â†’ IP ë°´ ì˜ì‹¬. ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                                notifier.error(
                                    "IP ë°´ ì˜ì‹¬ - í¬ë¡¤ëŸ¬ ì¤‘ë‹¨",
                                    f"{sido_name} {address}\n"
                                    f"ë§ˆì§€ë§‰ ì„±ê³µ í˜ì´ì§€: {page_num - 1}\n"
                                    f"ì¬ê°œ ëª…ë ¹ì–´: --start-page {page_num} --end-page {actual_end}"
                                )
                                break
                            _random_delay(15.0, 30.0)
                            continue

                        consecutive_errors = 0

                        for i in range(row_count):
                            cells = rows.nth(i).locator("td")
                            row_data = []
                            for c in range(min(cells.count(), len(HEADERS))):
                                raw_text = cells.nth(c).text_content().strip()
                                header_name = HEADERS[c]
                                clean_val = re.sub(f"^{header_name}", "", raw_text).strip()
                                row_data.append(clean_val)
                            writer.writerow(row_data)

                        f.flush()

                        # ì§„í–‰ ìƒíƒœ ì €ì¥
                        if progress_file:
                            _save_progress(progress_file, page_num)

                        logger.info(f"âœ… ì§„í–‰ ì¤‘: {page_num}/{actual_end} í˜ì´ì§€ ì™„ë£Œ ({row_count}ê±´)")

                        # ê¸´ íœ´ì‹
                        if pages_done > 0 and pages_done % cfg.long_break_interval == 0:
                            break_sec = random.uniform(cfg.long_break_min, cfg.long_break_max)
                            logger.info(f"â˜• {cfg.long_break_interval}í˜ì´ì§€ ì™„ë£Œ â†’ {break_sec:.0f}ì´ˆ íœ´ì‹")
                            time.sleep(break_sec)

                    # í˜ì´ì§€ë³„ ì—ëŸ¬ ì²˜ë¦¬ + ë³µêµ¬
                    except Exception as page_error:
                        consecutive_errors += 1
                        logger.error(f"âš ï¸ {page_num}í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {page_error}")

                        if consecutive_errors >= max_consecutive_errors:
                            logger.error(
                                f"ğŸš¨ ì—°ì† {max_consecutive_errors}íšŒ ì˜¤ë¥˜. í¬ë¡¤ëŸ¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤."
                            )
                            notifier.error(
                                "í¬ë¡¤ëŸ¬ ì˜¤ë¥˜ë¡œ ì¤‘ë‹¨",
                                f"{sido_name} {address}\nì˜¤ë¥˜ í˜ì´ì§€: {page_num}\n"
                                f"ì—ëŸ¬: {page_error}\n"
                                f"ì¬ê°œ ëª…ë ¹ì–´: --start-page {page_num} --end-page {actual_end}"
                            )
                            break

                        logger.info(f"ğŸ”§ ë³µêµ¬ ì‹œë„ ì¤‘... ({consecutive_errors}/{max_consecutive_errors})")
                        _random_delay(20.0, 40.0)

                        try:
                            context.close()
                        except Exception:
                            pass

                        context, page = _create_context(browser, logger)
                        retry_total = _setup_search(page)
                        if retry_total > 0:
                            _navigate_to_page(page, page_num, logger)
                            logger.info(f"ğŸ”§ ë³µêµ¬ ì„±ê³µ. {page_num}í˜ì´ì§€ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                            continue
                        else:
                            logger.error("ğŸ”§ ë³µêµ¬ ì‹¤íŒ¨.")
                            break

            last_done = _load_progress(progress_file) if progress_file else actual_end
            is_complete = (last_done >= actual_end)  
            if is_complete:
                notifier.success(
                    "ì‘ì—… ì™„ë£Œ âœ…",
                    f"{sido_name} {address} ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ\n"
                    f"ë²”ìœ„: {start_page}~{actual_end}p / ì „ì²´ {total_pages}p"
                )
            else:
                notifier.error(
                    "ë¶€ë¶„ ì™„ë£Œ âš ï¸",
                    f"{sido_name} {address}\n"
                    f"ì™„ë£Œ: {last_done}p / ëª©í‘œ: {actual_end}p\n"
                    f"ì¬ê°œ: --auto-resume"
                )
            context.close()
            browser.close()
            return is_complete

    except Exception as e:
        logger.error(f"ğŸš¨ í¬ë¡¤ëŸ¬ ì¤‘ë‹¨ë¨: {str(e)}")
        notifier.error("ì‹í’ˆì•ˆì „ë‚˜ë¼ í¬ë¡¤ëŸ¬ ì¤‘ë‹¨",
                        f"{e}\nì¬ê°œ: --start-page {start_page} --end-page {end_page or 'ë'}")
        if 'browser' in locals():
            browser.close()
        raise e


def main():
    parser = argparse.ArgumentParser(description="ì‹í’ˆì•ˆì „ë‚˜ë¼ ì‹ë‹¹ ëŒ€í‘œì í¬ë¡¤ëŸ¬")
    parser.add_argument("--sido", type=str, default="ê²½ê¸°ë„")
    parser.add_argument("--addr", type=str, default="")
    parser.add_argument("--start-page", type=int, default=1, help="ì‹œì‘ í˜ì´ì§€ (ê¸°ë³¸: 1)")           
    parser.add_argument("--end-page", type=int, default=None, help="ë í˜ì´ì§€ (ê¸°ë³¸: ì „ì²´)")          
    parser.add_argument("--auto-resume", action="store_true", help="ì´ì „ ì§„í–‰ ìƒíƒœì—ì„œ ìë™ ì¬ê°œ")  
    args = parser.parse_args()

    now = datetime.now()
    year = now.strftime("%Y")
    month = now.strftime("%m")
    region = args.sido[:2]

    base_path = Path(Config.project_root)
    work_dir = base_path / f"_work/year={year}/month={month}/region={region}"
    parquet_dir = base_path / f"parquet/year={year}/month={month}/region={region}"

    work_dir.mkdir(parents=True, exist_ok=True)
    parquet_dir.mkdir(parents=True, exist_ok=True)

    safe_addr = args.addr.replace(" ", "_")
    log_file = work_dir / f"run_{region}_{safe_addr}.log"
    csv_file = work_dir / f"{region}_{safe_addr}.csv"
    parquet_file = parquet_dir / f"{region}_{safe_addr}.parquet"
    progress_file = work_dir / f"progress_{region}_{safe_addr}.txt"  # 

    logger = build_logger(log_file)

    start_page = args.start_page
    end_page = args.end_page

    if args.auto_resume and progress_file.exists():
        saved = _load_progress(progress_file)
        if saved > 0:
            start_page = max(start_page, saved + 1)
            logger.info(f"ğŸ”„ ìë™ ì¬ê°œ ëª¨ë“œ: {saved}í˜ì´ì§€ê¹Œì§€ ì™„ë£Œ â†’ {start_page}í˜ì´ì§€ë¶€í„° ì‹œì‘")

    crawl_complete = False

    # í¬ë¡¤ë§ ë‹¨ê³„
    if start_page == 1 and csv_file.exists() and not args.auto_resume:
        logger.info(f"â­ï¸  ì´ë¯¸ CSV íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤. í¬ë¡¤ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤: {csv_file.name}")
        logger.info(f"   (ì¬ê°œí•˜ë ¤ë©´ --auto-resume ë˜ëŠ” --start-page N ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”)")
        crawl_complete = True
    else:
        logger.info(f"ğŸš€ í¬ë¡¤ë§ ì‹œì‘: {args.sido} {args.addr} (í˜ì´ì§€ {start_page}~{end_page or 'ë'})")
        crawl_complete = search_and_save_all_pages(
            sido_name=args.sido,
            address=args.addr,
            cfg=Config(),
            logger=logger,
            output_file=csv_file,
            start_page=start_page,
            end_page=end_page,
            progress_file=progress_file if args.auto_resume else None,
        )

    # ë³€í™˜ ë‹¨ê³„: í¬ë¡¤ë§ì´ ì „ì²´ ì™„ë£Œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
    if not crawl_complete:
        logger.info("â¸ï¸  í¬ë¡¤ë§ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Parquet ë³€í™˜ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        logger.info(f"   ì¬ê°œí•˜ë ¤ë©´: --auto-resume ë˜ëŠ” --start-page {start_page}")
        return

    if parquet_file.exists():
        logger.info(f"â­ï¸  ì´ë¯¸ Parquet íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤: {parquet_file.name}")
    elif csv_file.exists():
        try:
            logger.info("ğŸ“„ CSVë¥¼ Parquetë¡œ ë³€í™˜ ì¤‘...")
            df = pd.read_csv(csv_file)
            df.to_parquet(parquet_file, engine='pyarrow', index=False, compression='snappy')
            logger.info(f"âœ… ë³€í™˜ ì™„ë£Œ: {parquet_file}")

            # ì™„ë£Œ í›„ progress íŒŒì¼ ì •ë¦¬
            if progress_file and progress_file.exists():
                progress_file.unlink()
                logger.info("ğŸ§¹ progress íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ Parquet ë³€í™˜ ì‹¤íŒ¨: {e}")
    else:
        logger.error("âš ï¸ ë³€í™˜í•  CSV íŒŒì¼ì´ ì—†ì–´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")

def run_workflow(**kwargs):
    # 1. UI(conf)ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’ ì„¤ì •)
    conf = kwargs.get('dag_run').conf or {}

    sido = conf.get('sido', 'ê²½ê¸°ë„')
    addr = conf.get('addr', '')
    start_page = conf.get('start_page', 1)  # ë³€ìˆ˜ëª… í†µì¼ (Pythonic)
    end_page = conf.get('end_page', None)    # Noneì´ë©´ ì „ì²´ í¬ë¡¤ë§
    auto_resume = conf.get('auto_resume', True)

    # 2. sys.argv ì¡°ì‘ (mainì˜ argparseê°€ ì½ì„ ìˆ˜ ìˆë„ë¡)
    import sys
    sys.argv = [sys.argv[0], "--sido", sido, "--addr", addr]

    # ìˆ«ìí˜• ì¸ìë“¤ ì¶”ê°€
    sys.argv.extend(["--start-page", str(start_page)])
    if end_page:
        sys.argv.extend(["--end-page", str(end_page)])
    if auto_resume:
        sys.argv.append("--auto-resume")

    # 3. ë©”ì¸ ë¡œì§ ì‹¤í–‰
    print(f"ğŸš€ Airflowì—ì„œ ì „ë‹¬ë°›ì€ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰: {sys.argv}")
    main()

if __name__ == "__main__":
    main()
