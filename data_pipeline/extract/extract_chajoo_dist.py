import os
import sys
import time
import re
import logging
import zipfile
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, List, Iterable
from datetime import date
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from dotenv import load_dotenv

SIDO_WEIGHT = 0.7
SIGUNGU_WEIGHT = 0.3

# slack_utils.py ê²½ë¡œ ì¶”ê°€ (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€)
sys.path.append(str(Path(__file__).resolve().parent.parent.parent))
from data_pipeline.utils.slack_utils import SlackNotifier


# =========================
# ENV & Config
# =========================
load_dotenv()

@dataclass
class Config:
    # 1. ì°¨ì£¼ë¶„í¬ (ê¸°ì¡´)
    url_chajoo: str = "https://stat.molit.go.kr/portal/cate/statView.do?hRsId=58&hFormId=5498&hSelectId=5498&sStyleNum=2&sStart=202601&sEnd=202601&hPoint=00&hAppr=1"
    # 2. ìƒˆë¡œìš´ URL (ìë™ì°¨ ë“±ë¡í˜„í™© ë“±)
    url_area: str = "https://stat.molit.go.kr/portal/cate/statView.do?hRsId=24&hFormId=2300&hDivEng=&month_yn="

    project_root: str = "data/bronze/chajoo_dist"
    retries: int = 3
    timeout_sec: int = 120
    headless: bool = True
    sigungu_mapping_csv: str = "data/bronze/chajoo_dist/_work/SHP_CD_mapping.csv"
    slack_webhook_url: Optional[str] = os.getenv("SLACK_WEBHOOK_URL")
    force_run: bool = False

# =========================
# Logger & Helpers
# =========================
def build_logger(log_file: Path) -> logging.Logger:
    logger = logging.getLogger("chajoo_extract")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    fmt = logging.Formatter("%(asctime)s | %(levelname)s | %(message)s", "%Y-%m-%d %H:%M:%S")
    
    sh = logging.StreamHandler(sys.stdout)
    sh.setFormatter(fmt)
    # ë¡œê·¸ íŒŒì¼ ë¶€ëª¨ ë””ë ‰í† ë¦¬ ìƒì„± ë³´ì¥
    log_file.parent.mkdir(parents=True, exist_ok=True)
    fh = logging.FileHandler(log_file, encoding="utf-8")
    fh.setFormatter(fmt)
    
    logger.addHandler(sh)
    logger.addHandler(fh)
    return logger

def init_run_dirs(cfg: Config, yyyymm: str) -> dict:
    """used_yyyymm (YYYYMM) ê¸°ë°˜ìœ¼ë¡œ íŒŒí‹°ì…”ë‹ëœ ê²½ë¡œ ìƒì„± ë° ì„¸ë¶€ ë°ì´í„° í´ë” ë¶„ë¦¬"""
    base = Path(cfg.project_root)
    year = yyyymm[:4]
    month = yyyymm[4:6]

    # ê³µí†µ íŒŒí‹°ì…˜ ê²½ë¡œ
    partition_path = f"year={year}/month={month}"
    work_base = base / "_work" / partition_path

    paths = {
        "base": base,
        "work": work_base,
        # âœ… ìš”ì²­í•˜ì‹  ì„¸ë¶€ ê²½ë¡œ ì¶”ê°€
        "chajoo_xlsx": work_base / "chajoo",
        "log_file": work_base / "run.log",
        "parquet": base / "parquet" / partition_path,
        "gold": Path("data/gold/chajoo_dist") / partition_path,
    }

    # í•„ìš”í•œ ëª¨ë“  ë””ë ‰í† ë¦¬ ìƒì„±
    # area_xlsxì™€ chajoo_xlsxë¥¼ í¬í•¨í•˜ì—¬ ìƒì„±
    for key in ["chajoo_xlsx", "parquet", "gold"]:
        paths[key].mkdir(parents=True, exist_ok=True)

    return paths

# =========================
# Data Processing Helpers (New)
# =========================
def flatten_col(col: Iterable) -> str:
    """MultiIndex ì»¬ëŸ¼ì„ ë‹¨ì¼ ë¬¸ìì—´ë¡œ í‰íƒ„í™” ë° ì—°ì† ì¤‘ë³µ ì œê±°"""
    parts: List[str] = []
    for x in col:
        s = str(x).strip()
        if s.lower() in ("nan", "none", ""):
            continue
        if not parts or parts[-1] != s:
            parts.append(s)
    return "_".join(parts)

def pick_col(cands: List[str], columns: List[str]) -> str:
    """ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ í›„ë³´ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ì²« ë²ˆì§¸ ì»¬ëŸ¼ ë°˜í™˜"""
    for key in cands:
        hit = [c for c in columns if key in c]
        if hit:
            return hit[0]
    raise KeyError(f"í•„ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í›„ë³´={cands}")

# =========================
# Selenium & Download Logic
# =========================
def build_driver(download_dir: Path, cfg: Config) -> webdriver.Chrome:
    opts = Options()

    # -------------------------
    # í™˜ê²½ë³„ ë¶„ê¸° (í•µì‹¬)
    # -------------------------
    if os.path.exists("/usr/bin/chromium"):
        # âœ… ì»¨í…Œì´ë„ˆ (Airflow / Linux)
        opts.binary_location = "/usr/bin/chromium"
        service = Service("/usr/bin/chromedriver")
    else:
        # âœ… ë¡œì»¬ (macOS / Windows)
        service = Service()  # Selenium ìë™ íƒìƒ‰

    if cfg.headless:
        opts.add_argument("--headless=new")

    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--window-size=1400,1000")
    opts.add_experimental_option("excludeSwitches", ["enable-automation"])
    opts.add_experimental_option("useAutomationExtension", False)

    prefs = {
        "download.default_directory": str(download_dir.resolve()),
        "download.prompt_for_download": False,
        "download.directory_upgrade": True,
        "safebrowsing.enabled": True,
    }
    opts.add_experimental_option("prefs", prefs)

    driver = webdriver.Chrome(service=service, options=opts)
    driver.set_page_load_timeout(60)
    return driver

def is_xlsx_zip(path: Path) -> bool:
    try:
        with path.open("rb") as f:
            sig = f.read(2)
        return sig == b"PK" and zipfile.is_zipfile(path)
    except Exception:
        return False

def set_period_and_query(
    driver,
    logger,
    yyyymm: str | None = None,
    wait_timeout: int = 30,
):
    wait = WebDriverWait(driver, wait_timeout)

    # 1. ê¸°ì¡´ í…Œì´ë¸” ë° select ì—˜ë¦¬ë¨¼íŠ¸ í™•ë³´
    old_table = None
    try:
        old_table = driver.find_element(By.XPATH, "//table")
    except Exception:
        pass

    period_re = re.compile(r"^(\d{6}|\d{4})$")
    selects = wait.until(EC.presence_of_all_elements_located((By.XPATH, "//select")))
    period_selects = []

    for s in selects:
        try:
            sel = Select(s)
            values = [o.get_attribute("value") for o in sel.options if o.get_attribute("value")]
            month_vals = [v for v in values if period_re.match(v)]
            # ì›” ì˜µì…˜ì´ ì¶©ë¶„íˆ ë§ì€ selectë§Œ ì±„íƒ
            if len(month_vals) >= 10:
                period_selects.append((s, month_vals))
        except Exception:
            continue

    if len(period_selects) < 2:
        raise RuntimeError("ê¸°ê°„ì„ íƒ(ì‹œì‘/ë) select ìƒìë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    start_el, start_vals = period_selects[0]
    end_el, _ = period_selects[1]
    
    # ê°€ìš© ì˜µì…˜ ì—­ìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
    available_vals = sorted(start_vals, reverse=True)
    
    # 3. ë°ì´í„° í˜•ì‹ íŒë³„ ë° ìš”ì²­ê°’ ê°€ê³µ (YYYYMM -> YYYY)
    is_yearly = len(available_vals[0]) == 4
    requested_val = yyyymm[:4] if is_yearly and yyyymm else yyyymm

    # 4. ğŸ”¥ í´ë°± ë¡œì§: 2026ì„ ìš”ì²­í–ˆìœ¼ë‚˜ ìµœì‹ ì´ 2024ì¸ ê²½ìš° ëŒ€ì‘
    if not requested_val:
        target_val = available_vals[0]
        logger.info(f"ê¸°ê°„ ë¯¸ì§€ì • -> ìµœì‹  í•­ëª© ìë™ ì„ íƒ: {target_val}")
    elif requested_val in available_vals:
        target_val = requested_val
        logger.info(f"ìš”ì²­ ê¸°ê°„ ì„¤ì •: {target_val}")
    else:
        # ìš”ì²­ê°’ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì€ ê°’ ì¤‘ ê°€ì¥ ìµœì‹ ê°’ ì„ íƒ (2026 ìš”ì²­ ì‹œ 2024 ì„ íƒ)
        fallback_vals = [v for v in available_vals if v <= requested_val]
        target_val = fallback_vals[0] if fallback_vals else available_vals[0]
        logger.warning(f"âš ï¸ {requested_val} ë°ì´í„° ì—†ìŒ -> ê°€ìš© ìµœì‹  ë°ì´í„° {target_val}ë¡œ ëŒ€ì²´")

    # 5. ê°’ ì„ íƒ
    Select(start_el).select_by_value(target_val)
    Select(end_el).select_by_value(target_val)

    # 6. ì¡°íšŒ ë²„íŠ¼ í´ë¦­ (Intercepted ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ JS í´ë¦­ ê¶Œì¥)
    query_btn = wait.until(
        EC.element_to_be_clickable((By.XPATH, "//button[normalize-space()='ì¡°íšŒ']"))
    )

    # í™”ë©´ ê°€ë¦¼ë§‰(mu-dialog-background) ë¬´ì‹œí•˜ê³  í´ë¦­
    driver.execute_script("arguments[0].click();", query_btn)

    # 7. í…Œì´ë¸” ê°±ì‹  ëŒ€ê¸°
    if old_table:
        try:
            wait.until(EC.staleness_of(old_table))
        except Exception:
            pass

    wait.until(EC.presence_of_element_located((By.XPATH, "//table")))
    time.sleep(1.5)

    return target_val


def wait_for_download(download_dir: Path, timeout: int) -> Path:
    end = time.time() + timeout
    while time.time() < end:
        # .xlsx íŒŒì¼ë§Œ í•„í„°ë§ (ì„ì‹œ íŒŒì¼ .crdownload ì œì™¸)
        files = list(download_dir.glob("*.xlsx"))
        files = [f for f in files if not f.name.endswith(".crdownload")]

        if files:
            latest = max(files, key=lambda p: p.stat().st_mtime)
            # [ì¤‘ìš”] íŒŒì¼ ì“°ê¸°ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ ì²´í¬ (í¬ê¸° ë³€í™” ê´€ì°°)
            prev_size = -1
            for _ in range(5): 
                curr_size = latest.stat().st_size
                if curr_size > 0 and curr_size == prev_size:
                    return latest
                prev_size = curr_size
                time.sleep(0.5)
        time.sleep(1.0)

def perform_download(
    driver,
    logger,
    cfg,
    download_dir: Path,
    yyyymm: str | None = None,
) -> Path:
    wait = WebDriverWait(driver, 30)

    for attempt in range(1, cfg.retries + 1):
        try:
            logger.info(f"ë‹¤ìš´ë¡œë“œ ì‹œë„ ({attempt}/{cfg.retries})")

            if yyyymm:
                used_yyyymm = set_period_and_query(driver, logger, yyyymm)
            else:
                used_yyyymm = yyyymm

            start_ts = time.time()

            btn = wait.until(EC.element_to_be_clickable(
                (By.XPATH, "//button[@title='íŒŒì¼ ë‹¤ìš´ë¡œë“œ' or normalize-space()='íŒŒì¼ ë‹¤ìš´ë¡œë“œ']")
            ))
            btn.click()

            # ëª¨ë‹¬ í‘œì‹œ ëŒ€ê¸°
            wait.until(EC.visibility_of_element_located(
                (By.ID, "file-download-modal")
            ))

            # ğŸ”¥ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ì§ì ‘ ì‹¤í–‰ (ê°€ì¥ ì•ˆì •ì )
            driver.execute_script("download();")

            path = wait_for_download(download_dir, cfg.timeout_sec)
            if path.stat().st_mtime >= start_ts:
                logger.info(f"ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {path.name}")
                return path, used_yyyymm

        except Exception as e:
            logger.warning(f"ì‹œë„ {attempt} ì‹¤íŒ¨: {e}")
            if attempt < cfg.retries:
                driver.refresh()
                time.sleep(3)
            else:
                raise



# =========================
# Parquet Conversion
# =========================
SIDO_CODE_MAP = {
    "11": "ì„œìš¸",
    "26": "ë¶€ì‚°",
    "27": "ëŒ€êµ¬",
    "28": "ì¸ì²œ",
    "29": "ê´‘ì£¼",
    "30": "ëŒ€ì „",
    "31": "ìš¸ì‚°",
    "36": "ì„¸ì¢…",
    "41": "ê²½ê¸°",
    "42": "ê°•ì›",
    "43": "ì¶©ë¶",
    "44": "ì¶©ë‚¨",
    "45": "ì „ë¶",
    "46": "ì „ë‚¨",
    "47": "ê²½ë¶",
    "48": "ê²½ë‚¨",
    "50": "ì œì£¼",
}

# def convert_xlsx_to_parquet(
#     xlsx_chajoo_path: Path,
#     xlsx_area_path:Path,
#     out_dir_root: Path,
#     gold_dir_root: Path,
#     cfg: "Config",
#     logger: logging.Logger,
#     yyyymm: str,   # "YYYYMM"
# ) -> str:
#     """
#     ì—‘ì…€ -> ì „ì²˜ë¦¬ -> (year=YYYY/month=MM)/part.parquet ì €ì¥
#     - yyyymmìœ¼ë¡œ íŒŒí‹°ì…˜ ì €ì¥ ìœ„ì¹˜ë§Œ ê²°ì •
#     - parquetê°€ ì´ë¯¸ ìˆìœ¼ë©´ skip (force_run ì•„ë‹ˆë©´)
#     """

#     logger.info(f"ğŸ“¦ ì „ì²˜ë¦¬ ì‹œì‘: {xlsx_chajoo_path.name} & {xlsx_area_path.name} (yyyymm={yyyymm})")

#     # --------------------------------------------------
#     # 0. íŒŒí‹°ì…˜ ê²½ë¡œ/íŒŒì¼ ë¯¸ë¦¬ ê²°ì • + skip
#     # --------------------------------------------------
#     yyyymm = str(yyyymm).strip()
#     if len(yyyymm) != 6 or not yyyymm.isdigit():
#         raise ValueError(f"yyyymm í˜•ì‹ì´ ì´ìƒí•¨: {yyyymm} (ì˜ˆ: '202601')")

#     year_str = yyyymm[:4]
#     month_str = yyyymm[4:6]

#     partition_dir = out_dir_root
#     partition_dir.mkdir(parents=True, exist_ok=True)

#     gold_dir = gold_dir_root
#     gold_dir.mkdir(parents=True, exist_ok=True)

#     parquet_path = partition_dir / "part.parquet"
#     gold_parquet_path = gold_dir / "part.parquet"

#     if parquet_path.exists() and not cfg.force_run:
#         logger.info(f"â­ Parquet ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ë³€í™˜ ìŠ¤í‚µ: {parquet_path}")
#         return f"Skipped: {year_str}ë…„ {month_str}ì›” ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."

#     # --------------------------------------------------
#     # 1. ì—‘ì…€ ì½ê¸°
#     # --------------------------------------------------
#     # 1. ì—‘ì…€ ì½ê¸° ë° ì»¬ëŸ¼ í‰íƒ„í™”
#     chajoo_raw = pd.read_excel(xlsx_chajoo_path, header=[4, 5], engine="openpyxl")
#     area_raw = pd.read_excel(xlsx_area_path, header=[4, 5], engine="openpyxl")

#     for df in [chajoo_raw, area_raw]:
#         df.columns = [flatten_col(col) for col in df.columns] if isinstance(df.columns, pd.MultiIndex) else [str(c).strip() for c in df.columns]

#     # 2. ì°¨ì£¼ ë°ì´í„° ì „ì²˜ë¦¬ (chajoo)
#     c_sido = pick_col(["ì‹œë„ëª…"], list(chajoo_raw.columns))
#     c_sigungu = pick_col(["ì‹œêµ°êµ¬"], list(chajoo_raw.columns))
#     c_value = sorted([c for c in chajoo_raw.columns if "í™”ë¬¼" in c and "ì˜ì—…ìš©" in c], key=len)[0]

#     chajoo_df = chajoo_raw[[c_sido, c_sigungu, c_value]].copy()
#     chajoo_df.columns = ["sido", "sigungu", "cargo_count"]

#     # 3. ë©´ì  ë°ì´í„° ì „ì²˜ë¦¬ (area)
#     a_sido = pick_col(["ì‹œë„"], list(area_raw.columns))
#     a_sigungu = pick_col(["ì‹œêµ°êµ¬"], list(area_raw.columns))
#     # 'ë©´ì ' í‚¤ì›Œë“œê°€ ë“¤ì–´ê°„ ì»¬ëŸ¼ ì„ íƒ (ë³´í†µ 'ì†Œê³„_ë©´ì ' ë˜ëŠ” 'ê³„_ë©´ì ')
#     a_value = sorted([c for c in area_raw.columns if "ë©´ì " in c], key=len)[0]

#     area_df = area_raw[[a_sido, a_sigungu, a_value]].copy()
#     area_df.columns = ["sido", "sigungu", "area_m2"]

#     # 4. ë°ì´í„° ì •ì œ (ìˆ«ì ë³€í™˜ ë° 'ê³„' í–‰ ì œê±°)
#     # 4-1. ê³µí†µ ì²˜ë¦¬: ê³µë°± ì œê±° ë° ë¬¸ìì—´ ë³€í™˜
#     for df in [chajoo_df, area_df]:
#         df["sido"] = df["sido"].astype(str).str.strip()
#         df["sigungu"] = df["sigungu"].astype(str).str.strip()

#     # 4-2. chajoo_df: 'ê³„' ë˜ëŠ” 'í•©ê³„'ê°€ í¬í•¨ëœ í–‰ ì œê±°
#     chajoo_df.drop(chajoo_df[chajoo_df["sigungu"].str.contains("ê³„|í•©ê³„")].index, inplace=True)

#     # 4-3. area_df: sidoì™€ sigunguê°€ ë™ì¼í•œ í–‰(í•´ë‹¹ ì‹œë„ í•©ê³„) ì œê±°
#     # ì¶”ê°€ë¡œ 'ê³„' ë‹¨ì–´ê°€ ë“¤ì–´ê°„ í–‰ë„ ì•ˆì „í•˜ê²Œ ì œê±°
#     area_df.drop(area_df[
#         (area_df["sido"] == area_df["sigungu"]) | 
#         (area_df["sigungu"].str.contains("ê³„|í•©ê³„"))
#     ].index, inplace=True)

#     # 4-4. ìˆ«ì ë³€í™˜
#     chajoo_df["cargo_count"] = pd.to_numeric(chajoo_df["cargo_count"].astype(str).str.replace(",", ""), errors="coerce").fillna(0)
#     area_df["area_m2"] = pd.to_numeric(area_df["area_m2"].astype(str).str.replace(",", ""), errors="coerce").fillna(0)

#     # 4-5. Joinì„ ìœ„í•œ í‚¤ ìƒì„± ë° ì„¸ì¢…ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
#     for df in [chajoo_df, area_df]:
#         # ëª¨ë“  ê³µë°± ì œê±° (ì•ˆì‚°ì‹œìƒë¡êµ¬ ë“± ëŒ€ì‘)
#         df["join_key"] = df["sigungu"].str.replace(" ", "")

#         # ğŸ”¥ ì„¸ì¢…ì‹œ ì˜ˆì™¸ ì²˜ë¦¬: 'ì„¸ì¢…'ì„ 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ'ë¡œ í†µì¼
#         df.loc[df["join_key"] == "ì„¸ì¢…", "join_key"] = "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ"

#     # 5. ë°ì´í„° ë³‘í•© (Join)
#     # sidoì™€ join_keyë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ë³‘í•© (ë‹¤ë¥¸ ì‹œë„ì— ê°™ì€ ì´ë¦„ì˜ ì‹œêµ°êµ¬ê°€ ìˆì„ ê²½ìš° ëŒ€ë¹„)
#     merged = pd.merge(
#         chajoo_df, 
#         area_df[['sido', 'join_key', 'area_m2']], 
#         on=["sido", "join_key"],
#         how="inner"
#     )
#     # 3. ì„ì‹œ í‚¤ ì‚­ì œ (chajoo_dfì˜ ì›ë˜ sido, sigunguë§Œ ë‚¨ìŒ)
#     merged.drop(columns=["join_key"], inplace=True)

#     # --------------------------------------------------
#     # ğŸ”¥ 6. ì§€í‘œ ê³„ì‚° (ë©´ì  ëŒ€ë¹„ ë°€ë„ ê¸°ë°˜ ê³„ì¸µì  Z-score)
#     # --------------------------------------------------
    
#     # 1) ì‹œêµ°êµ¬ë³„ ë°€ë„ ê³„ì‚°
#     merged["sig_density"] = merged["cargo_count"] / merged["area_m2"]

#     # 2) [ì‹œêµ°êµ¬ Z-score] ê°™ì€ ì‹œë„(sido) ë‚´ì—ì„œ ê³„ì‚°
#     # groupby().transform()ì„ ì‚¬ìš©í•˜ì—¬ ì‹œë„ë³„ í‰ê· /í‘œì¤€í¸ì°¨ë¥¼ í•´ë‹¹ ì‹œêµ°êµ¬ì— ë§¤ì¹­
#     def get_group_zscore(group):
#         if len(group) > 1 and group.std() != 0:
#             return (group - group.mean()) / group.std()
#         return 0  # ì‹œë„ ë‚´ ì‹œêµ°êµ¬ê°€ 1ê°œë¿ì´ê±°ë‚˜ í¸ì°¨ê°€ ì—†ìœ¼ë©´ 0 ì²˜ë¦¬ (ì˜ˆ: ì„¸ì¢…)

#     merged["sig_zscore"] = merged.groupby("sido")["sig_density"].transform(get_group_zscore)

#     # 3) [ì‹œë„ Z-score] ì „êµ­ ì‹œë„ë¼ë¦¬ ë¹„êµí•˜ì—¬ ê³„ì‚°
#     # ì‹œë„ë³„ ì „ì²´ í•©ê³„ ê¸°ë°˜ ë°€ë„ ì‚°ì¶œ
#     sido_agg = merged.groupby("sido").agg({
#         "cargo_count": "sum",
#         "area_m2": "sum"
#     }).reset_index()

#     sido_agg["sido_density"] = sido_agg["cargo_count"] / sido_agg["area_m2"]

#     # ì‹œë„ë¼ë¦¬ì˜ ë¶„í¬ì—ì„œ Z-score ì‚°ì¶œ
#     s_mean = sido_agg["sido_density"].mean()
#     s_std = sido_agg["sido_density"].std()
#     sido_agg["sido_zscore"] = (sido_agg["sido_density"] - s_mean) / s_std
    
#     # ê³„ì‚°ëœ ì‹œë„ Z-scoreë¥¼ ì›ë˜ merged ë°ì´í„°í”„ë ˆì„ì— ë§¤í•‘
#     merged = merged.merge(sido_agg[["sido", "sido_zscore", "sido_density"]], on="sido", how="left")

#     # 4) ìµœì¢… ì ìˆ˜ ì‚°ì¶œ (ê°€ì¤‘ì¹˜ ì ìš©)
#     # SIDO_WEIGHT = 0.6, SIGUNGU_WEIGHT = 0.4
#     merged["final_score"] = (0.6 * merged["sido_zscore"]) + (0.4 * merged["sig_zscore"])

#     # --------------------------------------------------
#     # ğŸ”¥ 3. ì‹œêµ°êµ¬ ì½”ë“œ ë§¤í•‘ (SHP_CD) - ì§ì ‘ ë§¤ì¹­ ë²„ì „
#     # --------------------------------------------------
#     logger.info("ğŸ”— ì‹œêµ°êµ¬ ì½”ë“œ ë§¤í•‘ ì‹œì‘ (Direct Match)")
#     mapping_df = pd.read_csv(cfg.sigungu_mapping_csv, dtype={'SHP_CD': str})

#     # ì§ì ‘ ê²€ì¦ëœ sido, sigunguë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
#     # mapping_dfì—ì„œ ì¤‘ë³µë  ìˆ˜ ìˆëŠ” sido, sigunguë¥¼ ì œì™¸í•˜ê³  SHP_CDë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     final_result = merged.merge(
#         mapping_df[['sido', 'sigungu', 'SHP_CD']], 
#         on=["sido", "sigungu"],
#         how="left"
#     )

#     # ë§¤í•‘ ì‹¤íŒ¨ í™•ì¸
#     if final_result["SHP_CD"].isna().any():
#         failed = final_result[final_result["SHP_CD"].isna()][["sido", "sigungu"]].drop_duplicates()
#         logger.warning(f"âš  ì‹œêµ°êµ¬ ì½”ë“œ ë§¤í•‘ ì‹¤íŒ¨: {len(failed)}ê°œ êµ¬ì—­ ì¡´ì¬\n{failed.to_string(index=False)}")

#     # --------------------------------------------------
#     # 4. ìµœì¢… Parquet ì €ì¥
#     # --------------------------------------------------
#     # ë¶ˆí•„ìš”í•´ì§„ ì„ì‹œ ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ ì •ë¦¬
#     if "join_key" in final_result.columns:
#         final_result.drop(columns=["join_key"], inplace=True)

#     final_result.to_parquet(parquet_path, index=False, compression="snappy")
#     final_result.to_parquet(gold_parquet_path, index=False, compression="snappy")

#     logger.info(f"ğŸ’¾ ìµœì¢… Parquet ì €ì¥ ì™„ë£Œ: {gold_parquet_path} (rows={len(final_result)})")

#     return f"{year_str}ë…„ {month_str}ì›” ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ"

def convert_xlsx_to_parquet(
    xlsx_chajoo_path: Path,
    out_dir_root: Path,
    gold_dir_root: Path,
    cfg: "Config",
    logger: logging.Logger,
    yyyymm: str,
) -> str:
    logger.info(f"ğŸ“¦ ì „ì²˜ë¦¬ ì‹œì‘: {xlsx_chajoo_path.name} (yyyymm={yyyymm})")

    # --- 0. ê²½ë¡œ ì„¤ì • ---
    yyyymm = str(yyyymm).strip()
    year_str, month_str = yyyymm[:4], yyyymm[4:6]
    
    parquet_path = out_dir_root / "part.parquet"
    gold_parquet_path = gold_dir_root / "part.parquet"

    if parquet_path.exists() and not cfg.force_run:
        return f"Skipped: {yyyymm} ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."

    # --- 1. ì—‘ì…€ ì½ê¸° (ì°¨ì£¼ ë°ì´í„°ë§Œ) ---
    chajoo_raw = pd.read_excel(xlsx_chajoo_path, header=[4, 5], engine="openpyxl")
    chajoo_raw.columns = [flatten_col(col) for col in chajoo_raw.columns] if isinstance(chajoo_raw.columns, pd.MultiIndex) else [str(c).strip() for c in chajoo_raw.columns]

    # --- 2. ê¸°ë³¸ ì „ì²˜ë¦¬ ---
    c_sido = pick_col(["ì‹œë„ëª…"], list(chajoo_raw.columns))
    c_sigungu = pick_col(["ì‹œêµ°êµ¬"], list(chajoo_raw.columns))
    c_value = sorted([c for c in chajoo_raw.columns if "í™”ë¬¼" in c and "ì˜ì—…ìš©" in c], key=len)[0]

    df = chajoo_raw[[c_sido, c_sigungu, c_value]].copy()
    df.columns = ["sido", "sigungu", "cargo_count"]
    
    # ê³µë°± ì œê±° ë° ê³„ í–‰ ì œê±°
    df["sido"] = df["sido"].astype(str).str.strip()
    df["sigungu"] = df["sigungu"].astype(str).str.strip()
    df = df[~df["sigungu"].isin(["ê³„", "í•©ê³„"])].copy()
    
    # ìˆ«ì ë³€í™˜
    df["cargo_count"] = pd.to_numeric(df["cargo_count"].astype(str).str.replace(",", ""), errors="coerce").fillna(0)

    # --------------------------------------------------
    # ğŸ”¥ 3. ê³„ì¸µì  Z-score ê³„ì‚° (ìˆœìˆ˜ ì°¨ì£¼ ìˆ˜ ê¸°ë°˜)
    # --------------------------------------------------
    
    # 1) [ì‹œêµ°êµ¬ Z-score] ê°™ì€ ì‹œë„(sido) ë‚´ì—ì„œ ì°¨ì£¼ ìˆ˜ í¸ì°¨ ê³„ì‚°
    def get_group_zscore(group):
        if len(group) > 1 and group.std() != 0:
            return (group - group.mean()) / group.std()
        return 0

    df["sig_zscore"] = df.groupby("sido")["cargo_count"].transform(get_group_zscore)

    # 2) [ì‹œë„ Z-score] ì „êµ­ ì‹œë„ë¼ë¦¬ ë¹„êµ (ì‹œë„ë³„ ì´ ì°¨ì£¼ ìˆ˜ ê¸°ì¤€)
    sido_agg = df.groupby("sido")["cargo_count"].sum().reset_index(name="sido_cargo_sum")
    
    s_mean = sido_agg["sido_cargo_sum"].mean()
    s_std = sido_agg["sido_cargo_sum"].std()
    sido_agg["sido_zscore"] = (sido_agg["sido_cargo_sum"] - s_mean) / s_std
    
    # ì›ë˜ ë°ì´í„°ì— ì‹œë„ ì ìˆ˜ ë§¤í•‘
    df = df.merge(sido_agg[["sido", "sido_zscore", "sido_cargo_sum"]], on="sido", how="left")

    # 3) ìµœì¢… ì ìˆ˜ ì‚°ì¶œ (ê°€ì¤‘ì¹˜ 0.6 : 0.4)
    df["ì „ëµì _ì¤‘ìš”ë„"] = (0.6 * df["sido_zscore"]) + (0.4 * df["sig_zscore"])


    # ì˜ˆì™¸ì²˜ë¦¬
    # 1. (ê²½ê¸°, ë¶€ì²œì‹œ) ë° (ê²½ë¶, êµ°ìœ„êµ°), (ì¶©ë¶, ì²­ì›êµ°) í–‰ ì œê±°
    # ~ ê¸°í˜¸ëŠ” ì¡°ê±´ì„ ë°˜ì „(not)ì‹œí‚µë‹ˆë‹¤.
    df = df[~(
        ((df['sido'] == 'ê²½ê¸°') & (df['sigungu'] == 'ë¶€ì²œì‹œ')) | 
        ((df['sido'] == 'ê²½ë¶') & (df['sigungu'] == 'êµ°ìœ„êµ°')) |
        ((df['sido'] == 'ì¶©ë¶') & (df['sigungu'] == 'ì²­ì›êµ°'))
    )].copy()


    # --- 4. ì‹œêµ°êµ¬ ì½”ë“œ ë§¤í•‘ (SHP_CD) ---
    mapping_df = pd.read_csv(cfg.sigungu_mapping_csv, dtype={'SHP_CD': str})
    final_result = df.merge(
        mapping_df[['sido', 'sigungu', 'SHP_CD']], 
        on=["sido", "sigungu"],
        how="left"
    )

    # --------------------------------------------------
    # ğŸ”¥ 5. ìµœì¢… ì»¬ëŸ¼ í•„í„°ë§ ë° ì €ì¥
    # --------------------------------------------------
    # ìš”ì²­í•˜ì‹  5ê°œ í•µì‹¬ ì»¬ëŸ¼ë§Œ ì„ íƒ (year, monthëŠ” íŒŒí‹°ì…˜ ì •ë³´ë¡œ í™œìš©ë˜ë¯€ë¡œ í•„ìš”ì‹œ í¬í•¨)
    target_cols = ["sido", "sigungu", "SHP_CD", "cargo_count", "ì „ëµì _ì¤‘ìš”ë„"]

    # ë§Œì•½ DB insertë¥¼ ìœ„í•´ year, monthë„ ìœ ì§€í•´ì•¼ í•œë‹¤ë©´ ì•„ë˜ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì„¸ìš”.
    # target_cols += ["year", "month"] 

    final_result = final_result[target_cols].copy()

    # ì €ì¥
    final_result.to_parquet(parquet_path, index=False, compression="snappy")
    final_result.to_parquet(gold_parquet_path, index=False, compression="snappy")

    logger.info(f"ğŸ’¾ í•µì‹¬ ë°ì´í„° 5ê°œ ì»¬ëŸ¼ ì €ì¥ ì™„ë£Œ: {gold_parquet_path}")
    logger.info(f"ğŸ“Š ì €ì¥ëœ ì»¬ëŸ¼: {list(final_result.columns)}")

    return f"{year_str}ë…„ {month_str}ì›” ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ"

# =========================
# Main Logic
# =========================
def main():
    cfg = Config()

    # 1. ëŒ€ìƒ ì›” ê²°ì •
    base_date = date.today()
    year_val, month_val = base_date.year, base_date.month
    target_yyyymm = f"{year_val - 1}12" if month_val == 1 else f"{year_val}{month_val-1:02d}"

    paths = init_run_dirs(cfg, target_yyyymm)
    logger = build_logger(paths["log_file"])
    notifier = SlackNotifier(cfg.slack_webhook_url, "EXTRACT-ì°¨ì£¼ì¸êµ¬ë°€ë„", logger)

    logger.info(f"===== EXTRACT START (Target: {target_yyyymm}) =====")

    # ë“œë¼ì´ë²„ ë³€ìˆ˜ ì´ˆê¸°í™” (finallyì—ì„œ ë‹«ê¸° ìœ„í•¨)
    driver_chajoo = None
    driver_area = None

    try:
        notifier.info("ì‘ì—… ì‹œì‘", f"{target_yyyymm[:4]}ë…„ {target_yyyymm[4:]}ì›” ë°ì´í„° ì¶”ì¶œ ì‹œì‘")

        # --------------------------------------------------
        # 1. ì°¨ì£¼ ë¶„í¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (chajoo í´ë”)
        # --------------------------------------------------
        logger.info("Step 1: ì°¨ì£¼ ë¶„í¬ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        driver_chajoo = build_driver(paths["chajoo_xlsx"], cfg)
        driver_chajoo.get(cfg.url_chajoo)

        path_chajoo, used_mm_chajoo = perform_download(
            driver_chajoo, logger, cfg, paths["chajoo_xlsx"], yyyymm=target_yyyymm
        )
        logger.info(f"Step 1 ì™„ë£Œ: {path_chajoo.name} (ì‹¤ì œìˆ˜ì§‘: {used_mm_chajoo})")


        # --------------------------------------------------
        # 2. ì§€ì—­ ë©´ì  (area í´ë”)
        # --------------------------------------------------
        # logger.info("Step 2: ì§€ì—­ ë©´ì  ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        # driver_area = build_driver(paths["area_xlsx"], cfg)
        # driver_area.get(cfg.url_area)

        # path_area, used_mm_area = perform_download(
        #     driver_area, logger, cfg, paths["area_xlsx"], yyyymm=target_yyyymm
        # )
        # logger.info(f"Step 2 ì™„ë£Œ: {path_area.name} (ì‹¤ì œìˆ˜ì§‘: {used_mm_area})")


        # --------------------------------------------------
        # [STEP 3] ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³‘í•© (ì´í›„ ë‹¨ê³„)
        # --------------------------------------------------
        status_msg = convert_xlsx_to_parquet(path_chajoo, paths["parquet"], paths["gold"], cfg, logger, target_yyyymm)
        logger.info(f"ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ: {status_msg}")

        notifier.success("ì „ì²´ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ", f"{target_yyyymm[:4]}ë…„ {target_yyyymm[4:]}ì›” ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")

    except Exception as e:
        error_msg = f"ì—ëŸ¬ ë°œìƒ: {str(e)}"
        logger.error(f"ğŸš¨ {error_msg}", exc_info=True)
        notifier.error("ì°¨ì£¼ì¸êµ¬ë°€ë„ ì¶”ì¶œ ì‹¤íŒ¨", error_msg)
        sys.exit(1)

    finally:
        # ì—ëŸ¬ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ë“œë¼ì´ë²„ ì¢…ë£Œ
        if driver_chajoo:
            driver_chajoo.quit()
            logger.info("driver_chajoo ì¢…ë£Œ")
        if driver_area:
            driver_area.quit()
            logger.info("driver_area ì¢…ë£Œ")
        logger.info("===== EXTRACT PROCESS FINISHED =====")

def run_workflow(**kwargs):
    cfg = Config(headless=True)
    main()

if __name__ == "__main__":
    main()