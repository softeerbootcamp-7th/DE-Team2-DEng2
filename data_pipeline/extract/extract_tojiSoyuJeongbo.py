import os
import sys
import json
import time
import shutil
import requests
import zipfile
import datetime as dt
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Tuple, List

import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq

from seleniumwire import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoAlertPresentException

from webdriver_manager.chrome import ChromeDriverManager

from dotenv import load_dotenv
load_dotenv()


import logging
from logging.handlers import RotatingFileHandler

# =========================================================
# ì‹œë„ ì½”ë“œ
# =========================================================

SIDO_CODE = {
    "ì„œìš¸":"11","ë¶€ì‚°":"26","ëŒ€êµ¬":"27","ì¸ì²œ":"28",
    "ê´‘ì£¼":"29","ëŒ€ì „":"30","ìš¸ì‚°":"31","ì„¸ì¢…":"36",
    "ê²½ê¸°":"41","ì¶©ë¶":"43","ì¶©ë‚¨":"44","ì „ë‚¨":"46",
    "ê²½ë¶":"47","ê²½ë‚¨":"48","ì œì£¼":"50",
    "ê°•ì›":"51","ì „ë¶":"52",
}
SIDO_NAME_MAP = {v: k for k, v in SIDO_CODE.items()}


# =========================================================
# Config
# =========================================================

@dataclass
class Config:
    ds_id: str = "12"
    cookie_path: str = "data_pipeline/extract/secrets/vworld_cookies.json"
    headless: bool = True
    work_dir: str = "data/tojiSoyuJeongbo/_work"
    out_dir: str = "data/tojiSoyuJeongbo/parquet"
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    format_select: str = "CSV"
    slack_webhook_url: Optional[str] = os.getenv("SLACK_WEBHOOK_URL")



# =========================================================
# Logger
# =========================================================

def build_logger(log_dir: Path) -> logging.Logger:
    # ë¡œê·¸ ì €ì¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    log_dir.mkdir(parents=True, exist_ok=True)
    log_path = log_dir / "run.log"

    logger = logging.getLogger("vworld")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()

    formatter = logging.Formatter(
        "%(asctime)s | %(levelname)s | %(message)s",
        "%Y-%m-%d %H:%M:%S",
    )

    # 1. ì½˜ì†” ì¶œë ¥
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    # 2. íŒŒì¼ ì €ì¥ (work_dir/run.log ì— ì €ì¥ë¨)
    file_handler = RotatingFileHandler(
        log_path, 
        maxBytes=10*1024*1024, 
        backupCount=5, 
        encoding="utf-8"
    )
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    return logger


def slack_notify(webhook_url: Optional[str], text: str, logger: logging.Logger):
    if not webhook_url:
        logger.warning("SLACK_WEBHOOK_URL not set")
        return
    try:
        r = requests.post(webhook_url, json={"text": text}, timeout=10)
        if r.status_code >= 400:
            logger.error(f"Slack notify failed: {r.status_code} {r.text}")
    except Exception as e:
        logger.error(f"Slack notify exception: {e}")


# =========================================================
# Date
# =========================================================

def previous_month_range() -> Tuple[str, str]:
    today = dt.date.today()
    first = today.replace(day=1)
    last = first - dt.timedelta(days=1)
    return last.replace(day=1).strftime("%Y-%m-%d"), last.strftime("%Y-%m-%d")


# =========================================================
# URL (ë„¤ê°€ ì¤€ êµ¬ì¡° ê·¸ëŒ€ë¡œ)
# =========================================================

def build_query_url(cfg: Config, start_date: str, end_date: str) -> str:
    return (
        "https://www.vworld.kr/dtmk/dtmk_ntads_s002.do"
        "?pageSize=10&pageUnit=10&listPageIndex=1"
        "&gidsCd=&searchKeyword=%ED%86%A0%EC%A7%80%EC%86%8C%EC%9C%A0%EC%A0%95%EB%B3%B4"
        "&svcCde=NA&gidmCd=&searchBrmCode=&datIde=&searchFrm="
        f"&dsId={cfg.ds_id}"
        "&searchSvcCde=&searchOrganization=&dataSetSeq=12"
        "&searchTagList=&pageIndex=1&sortType=00"
        "&datPageIndex=1&datPageSize=25"
        f"&startDate={start_date}&endDate={end_date}"
        "&sidoCd=&dsNm="
        f"&formatSelect={cfg.format_select}"
    )


# =========================================================
# Selenium Driver
# =========================================================
# ìˆ˜ì •ëœ get_driver í•¨ìˆ˜ì˜ ì¼ë¶€ë¶„
def get_driver(cfg: Config, download_dir: Path) -> webdriver.Chrome:
    opts = Options()

    # Chrome í”„ë¡œí•„ ê³ ì •
    opts.add_argument("--user-data-dir=/Users/apple/chrome-vworld-profile")

    # ìë™í™” ê°ì§€ ì™„í™”
    opts.add_experimental_option("excludeSwitches", ["enable-automation"])
    opts.add_experimental_option("useAutomationExtension", False)

    if cfg.headless:
        opts.add_argument("--headless=new")

    # ğŸ”¥ í•µì‹¬ ì„¤ì • ì¶”ê°€
    prefs = {
        "download.default_directory": str(download_dir.absolute()),
        "download.prompt_for_download": False,
        "download.directory_upgrade": True,
        # ì•„ë˜ ì¤„ì„ ì¶”ê°€í•˜ì„¸ìš”. 1ì€ í—ˆìš©, 2ëŠ” ì°¨ë‹¨ì…ë‹ˆë‹¤.
        "profile.default_content_setting_values.multiple_automatic_downloads": 1,
    }
    opts.add_experimental_option("prefs", prefs)

    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=opts,
    )
    driver.set_page_load_timeout(60)
    return driver


# =========================================================
# Cookies
# =========================================================

def load_cookies(driver: webdriver.Chrome, cookie_path: str) -> None:
    cookies = json.loads(Path(cookie_path).read_text(encoding="utf-8"))

    driver.get("https://www.vworld.kr/")
    time.sleep(1)

    for c in cookies:
        c = dict(c)
        for k in ["sameSite", "storeId", "hostOnly", "session"]:
            c.pop(k, None)

        if "expirationDate" in c:
            c["expiry"] = int(c["expirationDate"])
            c.pop("expirationDate", None)

        if "vworld.kr" in c.get("domain", ""):
            c["domain"] = ".vworld.kr"
            c.setdefault("path", "/")
            driver.add_cookie(c)

    driver.refresh()
    time.sleep(2)

    if "ë¡œê·¸ì•„ì›ƒ" not in driver.page_source:
        raise RuntimeError("ë¡œê·¸ì¸ ì‹¤íŒ¨ (ì¿ í‚¤ ë§Œë£Œ)")

def close_login_popup_if_any(driver, timeout=10):
    """
    ë¡œê·¸ì¸ ì§í›„ ëœ¨ëŠ” modal popupì„ ë‹«ëŠ”ë‹¤.
    vWorldëŠ” ì´ê±¸ ë‹«ì•„ì•¼ ë‚´ë¶€ ë¡œê·¸ì¸ ìƒíƒœê°€ ì™„ë£Œëœë‹¤.
    """
    t0 = time.time()
    while time.time() - t0 < timeout:
        try:
            # 'ë‹«ê¸°', 'í™•ì¸', 'ì˜¤ëŠ˜ í•˜ë£¨ ë³´ì§€ ì•Šê¸°' ë“±
            btns = driver.find_elements(
                By.XPATH,
                "//button[contains(., 'ë‹«ê¸°') or "
                "contains(., 'í™•ì¸') or "
                "contains(., 'ì˜¤ëŠ˜')]"
            )
            for b in btns:
                if b.is_displayed():
                    driver.execute_script("arguments[0].click();", b)
                    time.sleep(0.5)
                    return
        except Exception:
            pass
        time.sleep(0.5)


def wait_login_session_ready(driver, timeout=20):
    """
    UIê°€ ì•„ë‹ˆë¼ ì¿ í‚¤ ê¸°ì¤€ìœ¼ë¡œ ë¡œê·¸ì¸ ìƒíƒœ íŒë‹¨
    """
    t0 = time.time()
    while time.time() - t0 < timeout:
        cookies = driver.get_cookies()
        cookie_names = {c["name"] for c in cookies}

        # ğŸ”¥ vWorld ë¡œê·¸ì¸ ì‹œ í•­ìƒ ì¡´ì¬í•˜ëŠ” ì¿ í‚¤
        if any(name.lower().startswith(("sso", "login", "session")) for name in cookie_names):
            return

        time.sleep(0.5)

    # ë””ë²„ê¹…ìš© ë¡œê·¸
    raise RuntimeError(
        f"ë¡œê·¸ì¸ ì„¸ì…˜ ì•ˆì •í™” ì‹¤íŒ¨ - í˜„ì¬ ì¿ í‚¤: {cookie_names}"
    )

# =========================================================
# Download helpers
# =========================================================

def wait_download_finished(download_dir: Path, timeout=600) -> Path:
    t0 = time.time()
    last_size = -1
    stable = 0

    while time.time() - t0 < timeout:
        if list(download_dir.glob("*.crdownload")):
            time.sleep(1)
            continue

        files = list(download_dir.glob("*.zip"))
        if not files:
            time.sleep(1)
            continue

        f = max(files, key=lambda p: p.stat().st_mtime)
        size = f.stat().st_size

        if size == last_size and size > 0:
            stable += 1
        else:
            stable = 0

        last_size = size
        if stable >= 2:
            return f

        time.sleep(1)

    raise TimeoutError("ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ëŒ€ê¸° ì‹¤íŒ¨")


def _unique_path(path: Path) -> Path:
    if not path.exists():
        return path
    for i in range(1, 10000):
        p = path.with_name(f"{path.stem}__{i}{path.suffix}")
        if not p.exists():
            return p
    raise RuntimeError("íŒŒì¼ëª… ì¤‘ë³µ ê³¼ë‹¤")


# =========================================================
# í•µì‹¬: í•˜ë‚˜ì”© ë‹¤ìš´ë¡œë“œ
# =========================================================

def wait_new_zip_created(download_dir: Path, before: set, timeout=600) -> Path:
    t0 = time.time()
    while time.time() - t0 < timeout:
        # ë‹¤ìš´ë¡œë“œ ì¤‘ì´ë©´ ëŒ€ê¸°
        if list(download_dir.glob("*.crdownload")):
            time.sleep(1)
            continue

        now = set(download_dir.glob("*.zip"))
        new_files = now - before

        if new_files:
            # ìƒˆë¡œ ìƒê¸´ ê²ƒë§Œ ë°˜í™˜
            return max(new_files, key=lambda p: p.stat().st_mtime)

        time.sleep(1)

    raise TimeoutError("ìƒˆ zip íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")


def is_already_prefixed(fname: str) -> bool:
    # ì‹œë„ëª…ì´ ì´ë¯¸ ë§¨ ì•ì— ìˆìœ¼ë©´ True
    for name in SIDO_CODE.keys():
        if fname.startswith(name + "_"):
            return True
    return False


def click_each_row_download_one_by_one(
    driver,
    logger,
    zip_save_dir: Path,
):
    buttons = driver.find_elements(By.XPATH, "//button[normalize-space()='ë‹¤ìš´ë¡œë“œ']")
    saved = []

    for idx, btn in enumerate(buttons, start=1):
        logger.info(f"[{idx}/{len(buttons)}] ë‹¤ìš´ë¡œë“œ ì‹œì‘")

        # ğŸ”‘ ë‹¤ìš´ë¡œë“œ ì „ ìƒíƒœ ìŠ¤ëƒ…ìƒ·
        before = set(zip_save_dir.glob("*.zip"))

        driver.execute_script(
            "arguments[0].scrollIntoView({block:'center'});", btn
        )
        driver.execute_script("arguments[0].click();", btn)

        # ğŸ”‘ ë°˜ë“œì‹œ ìƒˆë¡œ ìƒê¸´ íŒŒì¼ë§Œ ì¡ëŠ”ë‹¤
        f = wait_new_zip_created(zip_save_dir, before)

        # ğŸ”’ ì´ë¯¸ prefix ìˆìœ¼ë©´ ìŠ¤í‚µ (ì´ì¤‘ ë°©ì–´)
        if is_already_prefixed(f.name):
            logger.warning(f"ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ìŠ¤í‚µ: {f.name}")
            continue

        target = zip_save_dir / f"{f.name}"

        logger.info(f"âœ”ï¸ ì €ì¥ ì™„ë£Œ: {target.name}")
        saved.append(target)

        # ì‚¬ëŒì²˜ëŸ¼ ì‰¬ê¸°
        time.sleep(3)

    return saved


# =========================================================
# CSV â†’ Parquet
# =========================================================

def read_csv_to_table(csv_path: Path) -> pa.Table:
    for enc in ("euc-kr", "cp949", "utf-8-sig"):
        try:
            df = pd.read_csv(csv_path, encoding=enc, low_memory=False)
            break
        except UnicodeDecodeError:
            continue

    for c in df.columns:
        if df[c].dtype == "object":
            df[c] = df[c].astype("string")

    return pa.Table.from_pandas(df, preserve_index=False)

def has_any_zip(zip_dir: Path) -> bool:
    return any(zip_dir.glob("*.zip"))

def has_any_csv(unzip_dir: Path) -> bool:
    return any(unzip_dir.glob("*.csv"))

def has_any_parquet(out_dir: Path, y: str, m: str) -> bool:
    base = out_dir / f"year={y}" / f"month={m}"
    return base.exists() and any(base.rglob("*.parquet"))


# =========================================================
# Main
# =========================================================

def run(cfg: Config, logger: logging.Logger) -> None:
    start_date, end_date = (
        (cfg.start_date, cfg.end_date)
        if cfg.start_date and cfg.end_date
        else previous_month_range()
    )
    
    # ğŸ”” ì•Œë¦¼ 1: ì‘ì—… ì‹œì‘
    slack_notify(cfg.slack_webhook_url, f"ğŸš€ V-World ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ({start_date} ~ {end_date})", logger)

    work_dir = Path(cfg.work_dir)
    zip_dir = work_dir / "per_row_zips" / f"{start_date}_to_{end_date}"
    unzip_dir = work_dir / "unzipped" / f"{start_date}_to_{end_date}"

    zip_dir.mkdir(parents=True, exist_ok=True)
    unzip_dir.mkdir(parents=True, exist_ok=True)

    y, m = start_date.split("-")[:2]

    driver = None
    try:
        # 1ï¸âƒ£ ZIP ë‹¤ìš´ë¡œë“œ ë‹¨ê³„
        if has_any_zip(zip_dir):
            logger.info("â­ ZIP íŒŒì¼ ì¡´ì¬ â†’ ë‹¤ìš´ë¡œë“œ ë‹¨ê³„ ìŠ¤í‚µ")
        else:
            driver = get_driver(cfg, zip_dir)
            load_cookies(driver, cfg.cookie_path)

            driver.get(build_query_url(cfg, start_date, end_date))
            WebDriverWait(driver, 40).until(
                EC.presence_of_element_located((By.XPATH, "//button[normalize-space()='ë‹¤ìš´ë¡œë“œ']"))
            )

            saved = click_each_row_download_one_by_one(driver, logger, zip_dir)
            # ğŸ”” ì•Œë¦¼ 2: ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
            slack_notify(cfg.slack_webhook_url, f"âœ… {len(saved)}ê°œì˜ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ", logger)

        # 2ï¸âƒ£ UNZIP ë‹¨ê³„
        if not has_any_csv(unzip_dir):
            logger.info("ğŸ”“ unzip ì‹œì‘")
            for zp in zip_dir.glob("*.zip"):
                with zipfile.ZipFile(zp) as zf:
                    zf.extractall(unzip_dir)

        # 3ï¸âƒ£ PARQUET ë‹¨ê³„
        if has_any_parquet(Path(cfg.out_dir), y, m):
            logger.info("â­ Parquet íŒŒì¼ ì¡´ì¬ â†’ ë³€í™˜ ë‹¨ê³„ ìŠ¤í‚µ")
        else:
            csv_files = list(unzip_dir.rglob("*.csv"))
            total_count = len(csv_files)
            logger.info(f"ğŸ“¦ CSV â†’ Parquet ë³€í™˜ ì‹œì‘ (ì´ {total_count}ê°œ)")

            for idx, csv in enumerate(csv_files, start=1):
                try:
                    sido_code = csv.stem.split("_")[2]
                    region = SIDO_NAME_MAP.get(sido_code, "ì•Œìˆ˜ì—†ìŒ")
                    
                    out = Path(cfg.out_dir) / f"year={y}" / f"month={m}" / f"region={region}"
                    out.mkdir(parents=True, exist_ok=True)

                    target_path = out / f"{csv.stem}.parquet"
                    pq.write_table(read_csv_to_table(csv), target_path)
                    logger.info(f"   â””â”€ âœ”ï¸ ì™„ë£Œ: {target_path.name}")

                except Exception as e:
                    # ğŸ”” ì•Œë¦¼ 3: ê°œë³„ íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨ (ì—ëŸ¬)
                    error_msg = f"âŒ ë³€í™˜ ì‹¤íŒ¨: {csv.name}\nì—ëŸ¬: {str(e)}"
                    logger.error(error_msg)
                    slack_notify(cfg.slack_webhook_url, error_msg, logger)

            # ğŸ”” ì•Œë¦¼ 4: ì „ì²´ ê³µì • ì™„ë£Œ
            slack_notify(cfg.slack_webhook_url, f"âœ¨ {y}ë…„ {m}ì›” ë°ì´í„° Parquet ë³€í™˜ ë° ì ì¬ ì™„ë£Œ!", logger)

        logger.info("âœ¨ ALL DONE")

    except Exception as e:
        # ğŸ”” ì•Œë¦¼ 5: ì¹˜ëª…ì  ì‹œìŠ¤í…œ ì—ëŸ¬
        critical_error = f"ğŸš¨ ì‹œìŠ¤í…œ ì¤‘ë‹¨ ì—ëŸ¬ ë°œìƒ!\në‚´ìš©: {str(e)}"
        logger.error(critical_error)
        slack_notify(cfg.slack_webhook_url, critical_error, logger)
        raise e

# =========================================================
# Entrypoint
# =========================================================

def main():
    # 1. ì„¤ì • ê°ì²´ ìƒì„±
    cfg = Config()
    
    # 2. ì„¤ì •ì„ ë°”íƒ•ìœ¼ë¡œ ë¡œê±° ìƒì„± (work_dir ê²½ë¡œ ì „ë‹¬)
    # Configì— ì •ì˜ëœ 'data/tojiSoyuJeongbo/_work' í´ë”ì— run.logê°€ ìƒê¹ë‹ˆë‹¤.
    logger = build_logger(Path(cfg.work_dir))
    
    # 3. ì‹¤í–‰
    logger.info("í”„ë¡œê·¸ë¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    run(cfg, logger)


if __name__ == "__main__":
    main()