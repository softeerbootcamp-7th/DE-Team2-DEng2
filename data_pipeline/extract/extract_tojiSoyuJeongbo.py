import os
import sys
import json
import time
import requests
import zipfile
import datetime as dt
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Tuple, List

import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq

from seleniumwire import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoAlertPresentException

from webdriver_manager.chrome import ChromeDriverManager

from dotenv import load_dotenv
load_dotenv()

# slack_utils.pyë¥¼ ì°¾ê¸° ìœ„í•´ ìƒìœ„ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).resolve().parent.parent))
try:
    from data_pipeline.utils.slack_utils import SlackNotifier
except ImportError:
    # íŒŒì¼ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ Mock í´ë˜ìŠ¤
    class SlackNotifier:
        def __init__(self, *args, **kwargs): pass
        def info(self, *args): print(f"[INFO] {args}")
        def success(self, *args): print(f"[SUCCESS] {args}")
        def error(self, *args): print(f"[ERROR] {args}")

import logging
from logging.handlers import RotatingFileHandler

# =========================================================
# ì‹œë„ ì½”ë“œ ë° ì„¤ì •
# =========================================================

SIDO_CODE = {
    "ì„œìš¸":"11","ë¶€ì‚°":"26","ëŒ€êµ¬":"27","ì¸ì²œ":"28",
    "ê´‘ì£¼":"29","ëŒ€ì „":"30","ìš¸ì‚°":"31","ì„¸ì¢…":"36",
    "ê²½ê¸°":"41","ì¶©ë¶":"43","ì¶©ë‚¨":"44","ì „ë‚¨":"46",
    "ê²½ë¶":"47","ê²½ë‚¨":"48","ì œì£¼":"50",
    "ê°•ì›":"51","ì „ë¶":"52",
}
# ì‹œë„ ì½”ë“œ(Value)ë¥¼ keyë¡œ í•˜ì—¬ ì§€ì—­ëª…(Key)ì„ ì°¾ëŠ” ë§µ
SIDO_NAME_MAP = {v: k for k, v in SIDO_CODE.items()}

@dataclass
class Config:
    ds_id: str = "12"
    cookie_path: str = "data_pipeline/extract/secrets/vworld_cookies.json"
    headless: bool = False
    work_dir: str = "data/tojiSoyuJeongbo/_work"
    out_dir: str = "data/tojiSoyuJeongbo/parquet"
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    format_select: str = "CSV"
    slack_webhook_url: Optional[str] = os.getenv("SLACK_WEBHOOK_URL")
    retries: int = 3
    retry_sleep_sec: int = 5
    timeout_sec: int = 60

# =========================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (Logger, Date, URL, Driver)
# =========================================================

def build_logger(log_dir: Path) -> logging.Logger:
    log_dir.mkdir(parents=True, exist_ok=True)
    log_path = log_dir / "run.log"
    logger = logging.getLogger("vworld")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    formatter = logging.Formatter("%(asctime)s | %(levelname)s | %(message)s", "%Y-%m-%d %H:%M:%S")
    
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    file_handler = RotatingFileHandler(log_path, maxBytes=10*1024*1024, backupCount=5, encoding="utf-8")
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    return logger

def previous_month_range() -> Tuple[str, str]:
    today = dt.date.today()
    first = today.replace(day=1)
    last = first - dt.timedelta(days=1)
    return last.replace(day=1).strftime("%Y-%m-%d"), last.strftime("%Y-%m-%d")

def build_query_url(cfg: Config, start_date: str, end_date: str) -> str:
    """
    vWorld í† ì§€ì†Œìœ ì •ë³´ ë°ì´í„°ì…‹ ì¡°íšŒë¥¼ ìœ„í•œ ìƒì„¸ URL ìƒì„±
    ì œì‹œí•´ì£¼ì‹  URLì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•˜ì—¬ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.
    """
    base_url = "https://www.vworld.kr/dtmk/dtmk_ntads_s002.do"

    params = {
        "pageSize": "10",
        "pageUnit": "25",
        "listPageIndex": "1",
        "gidsCd": "",
        "searchKeyword": "í† ì§€ì†Œìœ ì •ë³´",  # URL ì¸ì½”ë”©ì€ f-stringì´ë‚˜ params ì²˜ë¦¬ ì‹œ ìë™ ì ìš©
        "svcCde": "NA",
        "gidmCd": "",
        "searchBrmCode": "",
        "datIde": "",
        "searchFrm": "",
        "dsId": cfg.ds_id,
        "searchSvcCde": "",
        "searchOrganization": "",
        "dataSetSeq": cfg.ds_id,  # dsIdì™€ ë™ì¼í•˜ê²Œ 12ë¡œ ì„¤ì •ë¨
        "searchTagList": "",
        "pageIndex": "1",
        "sortType": "00",
        "datPageIndex": "1",
        "datPageSize": "50",
        "startDate": start_date,
        "endDate": end_date,
        "sidoCd": "",
        "dsNm": "",
        "formatSelect": cfg.format_select
    }

    # query string ìƒì„± (URL ì¸ì½”ë”© í¬í•¨)
    query_string = "&".join([f"{k}={v}" for k, v in params.items()])

    return f"{base_url}?{query_string}"



def get_driver(cfg: Config, download_dir: Path) -> webdriver.Chrome:
    opts = Options()
    opts.add_argument("--user-data-dir=/Users/apple/chrome-vworld-profile")
    if cfg.headless: opts.add_argument("--headless=new")
    prefs = {
        "download.default_directory": str(download_dir.absolute()),
        "download.prompt_for_download": False,
        "profile.default_content_setting_values.multiple_automatic_downloads": 1,
    }
    opts.add_experimental_option("prefs", prefs)
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)
    driver.set_page_load_timeout(cfg.timeout_sec)
    return driver

# =========================================================
# ì¿ í‚¤ ë° ë‹¤ìš´ë¡œë“œ ë¡œì§
# =========================================================

def load_cookies(driver: webdriver.Chrome, cfg: Config) -> None:
    if not Path(cfg.cookie_path).exists():
        raise FileNotFoundError(f"ì¿ í‚¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {cfg.cookie_path}")
    
    cookies = json.loads(Path(cfg.cookie_path).read_text(encoding="utf-8"))
    for attempt in range(1, cfg.retries + 1):
        driver.get("https://www.vworld.kr/")
        time.sleep(2)
        for c in cookies:
            c = dict(c)
            for k in ["sameSite", "storeId", "hostOnly", "session"]: c.pop(k, None)
            if "expirationDate" in c:
                c["expiry"] = int(c["expirationDate"])
                c.pop("expirationDate", None)
            if "vworld.kr" in c.get("domain", ""):
                c["domain"] = ".vworld.kr"
                driver.add_cookie(c)
        driver.refresh()
        time.sleep(3)
        if "ë¡œê·¸ì•„ì›ƒ" in driver.page_source: return
    raise RuntimeError("ë¡œê·¸ì¸ ì‹¤íŒ¨ (ì¿ í‚¤ ë§Œë£Œ í˜¹ì€ ì‚¬ì´íŠ¸ ì‘ë‹µ ì—†ìŒ)")

def wait_new_zip_created(download_dir: Path, before: set, timeout=600) -> Path:
    t0 = time.time()
    while time.time() - t0 < timeout:
        if list(download_dir.glob("*.crdownload")):
            time.sleep(2)
            continue
        now = set(download_dir.glob("*.zip"))
        new_files = now - before
        if new_files:
            return max(new_files, key=lambda p: p.stat().st_mtime)
        time.sleep(2)
    raise TimeoutError("ìƒˆ zip íŒŒì¼ ìƒì„± ëŒ€ê¸° ì´ˆê³¼")

def click_each_row_download_one_by_one(driver, logger, zip_save_dir: Path, limit: int = 17):
    all_buttons = driver.find_elements(By.XPATH, "//button[normalize-space()='ë‹¤ìš´ë¡œë“œ']")
    buttons = all_buttons[-limit:]
    logger.info(f"ëŒ€ìƒ ë°ì´í„° {len(buttons)}ê±´ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
    saved = []
    for idx, btn in enumerate(buttons, start=1):
        before = set(zip_save_dir.glob("*.zip"))
        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", btn)
        driver.execute_script("arguments[0].click();", btn)
        try:
            f = wait_new_zip_created(zip_save_dir, before)
            logger.info(f"âœ”ï¸ [{idx}/{len(buttons)}] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {f.name}")
            saved.append(f)
        except Exception as e:
            logger.error(f"âŒ [{idx}] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        time.sleep(3)
    return saved

# =========================================================
# ë°ì´í„° ë³€í™˜ (CSV -> Parquet)
# =========================================================

def read_csv_to_table(csv_path: Path) -> pa.Table:
    df = None
    for enc in ("euc-kr", "cp949", "utf-8-sig"):
        try:
            df = pd.read_csv(csv_path, encoding=enc, low_memory=False)
            break
        except UnicodeDecodeError: continue
    if df is None: raise ValueError(f"CSV ì¸ì½”ë”© í•´ì„ ì‹¤íŒ¨: {csv_path}")
    
    for c in df.columns:
        if df[c].dtype == "object":
            df[c] = df[c].astype("string")
    return pa.Table.from_pandas(df, preserve_index=False)

def has_any_zip(zip_dir: Path) -> bool: return any(zip_dir.glob("*.zip"))
def has_any_csv(unzip_dir: Path) -> bool: return any(unzip_dir.glob("*.csv"))
def has_any_parquet(out_dir: Path, y: str, m: str) -> bool:
    base = out_dir / f"year={y}" / f"month={m}"
    return base.exists() and any(base.rglob("*.parquet"))

# =========================================================
# Main Execution Logic
# =========================================================

def run(cfg: Config, logger: logging.Logger) -> None:
    notifier = SlackNotifier(cfg.slack_webhook_url, "EXTRACT-í† ì§€ì†Œìœ ì •ë³´", logger)
    start_date, end_date = (cfg.start_date, cfg.end_date) if cfg.start_date else previous_month_range()
    y, m = start_date.split("-")[:2]

    work_dir = Path(cfg.work_dir)
    zip_dir = work_dir / "per_row_zips" / f"{start_date}_to_{end_date}"
    unzip_dir = work_dir / "unzipped" / f"{start_date}_to_{end_date}"
    zip_dir.mkdir(parents=True, exist_ok=True)
    unzip_dir.mkdir(parents=True, exist_ok=True)

    driver = None
    success_count = 0
    is_skipped = False


    try:
        # [START]
        notifier.info("ì‘ì—… ì‹œì‘", f"ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")

        # 1ï¸âƒ£ ZIP ë‹¤ìš´ë¡œë“œ ë‹¨ê³„
        if has_any_zip(zip_dir):
            logger.warning("â­ ZIP íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        else:
            logger.info("ğŸŒ ë“œë¼ì´ë²„ ì„¸ì…˜ ì‹œì‘ ë° ì¿ í‚¤ ë¡œë“œ ì¤‘...")
            driver = get_driver(cfg, zip_dir)
            load_cookies(driver, cfg)

            logger.info(f"ğŸ” ë°ì´í„° ì¡°íšŒ í˜ì´ì§€ ì ‘ì†: {start_date} ~ {end_date}")
            driver.get(build_query_url(cfg, start_date, end_date))
            time.sleep(2)
            WebDriverWait(driver, 40).until(
                EC.presence_of_element_located((By.XPATH, "//button[normalize-space()='ë‹¤ìš´ë¡œë“œ']"))
            )

            saved_zips = click_each_row_download_one_by_one(driver, logger, zip_dir)
            logger.info(f"âœ… ZIP ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(saved_zips)}ê°œ íŒŒì¼")

        # 2ï¸âƒ£ UNZIP ë‹¨ê³„
        if has_any_csv(unzip_dir):
            logger.warning("â­ CSV íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ì••ì¶• í•´ì œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        else:
            logger.info("ğŸ”“ ì••ì¶• í•´ì œ(Unzip) ì‹œì‘...")
            for zp in zip_dir.glob("*.zip"):
                with zipfile.ZipFile(zp) as zf:
                    zf.extractall(unzip_dir)
            logger.info("âœ… ëª¨ë“  ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì™„ë£Œ")

        # 3ï¸âƒ£ PARQUET ë³€í™˜ ë‹¨ê³„
        if has_any_parquet(Path(cfg.out_dir), y, m):
            logger.warning(f"â­ {y}-{m} Parquet ê²°ê³¼ê°€ ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ë³€í™˜ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        else:
            csv_files = list(unzip_dir.rglob("*.csv"))
            logger.info(f"ğŸ“¦ CSV -> Parquet ë³€í™˜ ì‹œì‘ (ì´ {len(csv_files)}ê°œ)")

            success_count = 0
            for idx, csv in enumerate(csv_files, start=1):
                try:
                    sido_code = csv.stem.split("_")[2]
                    region = SIDO_NAME_MAP.get(sido_code, "Unknown")

                    out = Path(cfg.out_dir) / f"year={y}" / f"month={m}" / f"region={region}"
                    out.mkdir(parents=True, exist_ok=True)

                    target_path = out / f"{csv.stem}.parquet"
                    pq.write_table(read_csv_to_table(csv), target_path)
                    logger.info(f"   â””â”€ [{idx}/{len(csv_files)}] {region} ì™„ë£Œ")
                    success_count += 1

                except Exception as e:
                    logger.error(f"âŒ {csv.name} ë³€í™˜ ì¤‘ ê°œë³„ ì—ëŸ¬ ë°œìƒ: {e}")
                    # ê°œë³„ íŒŒì¼ ì‹¤íŒ¨ëŠ” loggerì—ë§Œ ë‚¨ê¸°ê³  ì§„í–‰í•˜ê±°ë‚˜, ì¤‘ìš”í•˜ë©´ ì•Œë¦¼ì„ ë³´ëƒ…ë‹ˆë‹¤.

            logger.info(f"âœ… ë³€í™˜ ê³µì • ì¢…ë£Œ (ì„±ê³µ: {success_count}/{len(csv_files)})")

        # [SUCCESS]
        notifier.success("ì‘ì—… ì™„ë£Œ", f"{y}ë…„ {m}ì›” ë°ì´í„° ì ì¬ì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤. (ì„±ê³µ: {success_count}ê±´)")

    except Exception as e:
        # [CRITICAL ERROR]
        logger.error(f"ğŸš¨ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨ë¨: {str(e)}")
        notifier.error("í† ì§€ì†Œìœ ì •ë³´ ìˆ˜ì§‘ ì¤‘ë‹¨ë¨", e)
        raise e

    finally:
        if driver:
            driver.quit()
            logger.info("ğŸ”’ ë“œë¼ì´ë²„ ì„¸ì…˜ì„ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")

def main():
    cfg = Config()
    logger = build_logger(Path(cfg.work_dir))
    logger.info("ğŸš€ íŒŒì´í”„ë¼ì¸ ê°€ë™")
    run(cfg, logger)

if __name__ == "__main__":
    main()
