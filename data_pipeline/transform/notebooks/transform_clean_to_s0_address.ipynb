{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d18657-34f7-4b5a-b001-b4076515bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, DoubleType\n",
    "from pyproj import Transformer\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from utils.spark_path import get_latest_year_month_path, get_current_year_month_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ed97a5-8f5f-4dc9-ac51-22119f203716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\n",
      "Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\n",
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/21 10:59:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"silver_clean_to_s0_address\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e23903-cf03-42f1-9c33-8ccd0416af21",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd113a04-7e06-40cd-b183-3e4dfed52140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PATH] address_src_path = /opt/spark/data/silver/clean/address/year=2026/month=02\n",
      "[PATH] coord_src_path   = /opt/spark/data/silver/clean/coord/year=2026/month=02\n",
      "[PATH] s0_address_path  = /opt/spark/data/silver/s0/address/year=2026/month=02\n",
      "[CONF] s0_partition_cols = ['region']\n"
     ]
    }
   ],
   "source": [
    "CONFIG_PATH = \"./config.yaml\"\n",
    "\n",
    "with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "ROOT = cfg[\"data_lake\"][\"root\"]\n",
    "LAYERS = cfg[\"data_lake\"][\"layers\"]\n",
    "\n",
    "# input\n",
    "address_clean_src_base = os.path.join(\n",
    "    ROOT,\n",
    "    LAYERS[\"silver\"][\"clean\"][\"domains\"][\"address_clean\"][\"paths\"][\"parquet\"]\n",
    ")\n",
    "address_clean_src_path = get_latest_year_month_path(spark, address_clean_src_base)\n",
    "\n",
    "coord_clean_src_base = os.path.join(\n",
    "    ROOT,\n",
    "    LAYERS[\"silver\"][\"clean\"][\"domains\"][\"coord_clean\"][\"paths\"][\"parquet\"]\n",
    ")\n",
    "coord_clean_src_path = get_latest_year_month_path(spark, coord_clean_src_base)\n",
    "\n",
    "\n",
    "# output\n",
    "s0_address_base = os.path.join(\n",
    "    ROOT,\n",
    "    LAYERS[\"silver\"][\"stages\"][\"s0\"][\"domains\"][\"address\"][\"paths\"][\"parquet\"]\n",
    ")\n",
    "s0_address_path = get_current_year_month_path(s0_address_base)\n",
    "\n",
    "s0_partition_cols = LAYERS[\"silver\"][\"stages\"][\"s0\"][\"domains\"][\"address\"].get(\"partition\")\n",
    "\n",
    "print(\"[PATH] address_src_path =\", address_clean_src_path)\n",
    "print(\"[PATH] coord_src_path   =\", coord_clean_src_path)\n",
    "print(\"[PATH] s0_address_path  =\", s0_address_path)\n",
    "print(\"[CONF] s0_partition_cols =\", s0_partition_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c482ae-794f-4a48-bb10-8f04062d00dd",
   "metadata": {},
   "source": [
    "# Bronze 데이터 로드 (도로명주소, 위치정보)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e5a2b8-dfce-43ad-8446-530e4c140ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PNU코드: string (nullable = true)\n",
      " |-- 도로명주소: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- 도로명주소: string (nullable = true)\n",
      " |-- x_utmk: double (nullable = true)\n",
      " |-- y_utmk: double (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LOAD\n",
    "# ============================================================\n",
    "addr_clean_df = spark.read.parquet(address_clean_src_path)\n",
    "coord_clean_df = spark.read.parquet(coord_clean_src_path)\n",
    "\n",
    "addr_clean_df.printSchema()\n",
    "coord_clean_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f59a65-5890-4798-b09e-9fb48df1c2ff",
   "metadata": {},
   "source": [
    "# 도로명주소, 위치정보 join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31249e72-92d0-4464-98e7-9421cf087023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined_df schema\n",
      "root\n",
      " |-- 도로명주소: string (nullable = true)\n",
      " |-- PNU코드: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- x_utmk: double (nullable = true)\n",
      " |-- y_utmk: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------+------+--------------+--------------+\n",
      "|도로명주소               |PNU코드            |region|x_utmk        |y_utmk        |\n",
      "+-------------------------+-------------------+------+--------------+--------------+\n",
      "|경기도 가평군 가랫골길 17|4182025031101400010|경기  |1000681.927311|1976146.147896|\n",
      "|경기도 가평군 가랫골길 22|4182025031106870000|경기  |1000668.204629|1976181.683314|\n",
      "|경기도 가평군 가랫골길 24|4182025031105080000|경기  |1000657.463751|1976191.74324 |\n",
      "|경기도 가평군 가랫골길 38|4182025031105100005|경기  |1000523.771708|1976229.485399|\n",
      "|경기도 가평군 가랫골길 9 |4182025031101400008|경기  |1000758.497104|1976124.261699|\n",
      "+-------------------------+-------------------+------+--------------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "joined_df = (\n",
    "    addr_clean_df\n",
    "    .join(coord_clean_df.drop(\"region\"), on=\"도로명주소\", how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"joined_df schema\")\n",
    "joined_df.printSchema()\n",
    "joined_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f2e46-fcd2-45d9-b3ad-89b909d4c86f",
   "metadata": {},
   "source": [
    "# 좌표 변환 (EPSG:5179 -> EPSG:4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eebd91c3-a155-4ada-afe0-ce28a2af5b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 도로명주소: string (nullable = true)\n",
      " |-- PNU코드: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- x_utmk: double (nullable = true)\n",
      " |-- y_utmk: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "@pandas_udf(schema)\n",
    "def utmk5179_to_wgs84(x: pd.Series, y: pd.Series) -> pd.DataFrame:\n",
    "    # ✅ executor에서 import + transformer 생성\n",
    "    from pyproj import Transformer\n",
    "    transformer = Transformer.from_crs(\"EPSG:5179\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "    # null 처리\n",
    "    mask = x.isna() | y.isna()\n",
    "    xx = x.astype(\"float64\")\n",
    "    yy = y.astype(\"float64\")\n",
    "\n",
    "    lon, lat = transformer.transform(xx, yy)\n",
    "\n",
    "    out = pd.DataFrame({\"latitude\": lat, \"longitude\": lon})\n",
    "    out.loc[mask, [\"latitude\", \"longitude\"]] = None\n",
    "    return out\n",
    "\n",
    "# 적용\n",
    "converted_df = (\n",
    "    joined_df\n",
    "    .withColumn(\"wgs84\", utmk5179_to_wgs84(F.col(\"x_utmk\"), F.col(\"y_utmk\")))\n",
    "    .withColumn(\"latitude\", F.col(\"wgs84.latitude\"))\n",
    "    .withColumn(\"longitude\", F.col(\"wgs84.longitude\"))\n",
    "    .drop(\"wgs84\")\n",
    ")\n",
    "\n",
    "converted_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb28668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-------------------------+------------------+------------------+\n",
      "|region|PNU코드            |도로명주소               |longitude         |latitude          |\n",
      "+------+-------------------+-------------------------+------------------+------------------+\n",
      "|경기  |4182025031101400010|경기도 가평군 가랫골길 17|127.50774450708117|37.78500342081887 |\n",
      "|경기  |4182025031106870000|경기도 가평군 가랫골길 22|127.50758869417821|37.785323719849806|\n",
      "|경기  |4182025031105080000|경기도 가평군 가랫골길 24|127.50746672085072|37.785414400065214|\n",
      "|경기  |4182025031105100005|경기도 가평군 가랫골길 38|127.5059484269042 |37.78575466522971 |\n",
      "|경기  |4182025031101400008|경기도 가평군 가랫골길 9 |127.50861407143987|37.784806095122065|\n",
      "+------+-------------------+-------------------------+------------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "joined_df = (\n",
    "    converted_df\n",
    "    .drop(\"x_utmk\", \"y_utmk\")\n",
    "    .select(\"region\", \"PNU코드\", \"도로명주소\", \"longitude\", \"latitude\")\n",
    ")\n",
    "\n",
    "joined_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d2b5f-8253-4a6d-960d-90a0b670d95a",
   "metadata": {},
   "source": [
    "# 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e52868-39d2-477e-818b-827e192a6fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved: /opt/spark/data/silver/s0/address/year=2026/month=02\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    joined_df\n",
    "    .write.mode(\"overwrite\")\n",
    "    .partitionBy(*s0_partition_cols)\n",
    "    .parquet(s0_address_path)\n",
    ")\n",
    "\n",
    "print(\"✅ saved:\", s0_address_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88697a4a-79a9-47d8-a248-03301a4271a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
