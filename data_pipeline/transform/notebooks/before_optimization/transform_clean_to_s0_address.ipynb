{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d18657-34f7-4b5a-b001-b4076515bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, DoubleType\n",
    "from pyproj import Transformer\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from utils.spark_path import get_latest_year_month_path, get_current_year_month_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ed97a5-8f5f-4dc9-ac51-22119f203716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\n",
      "Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\n",
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/20 20:23:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"silver_s0_address_upsert\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e23903-cf03-42f1-9c33-8ccd0416af21",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd113a04-7e06-40cd-b183-3e4dfed52140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PATH] address_src_path = /opt/spark/data/silver/clean/address/year=2026/month=02\n",
      "[PATH] coord_src_path   = /opt/spark/data/silver/clean/coord/year=2026/month=02\n",
      "[PATH] s0_address_path  = /opt/spark/data/silver/s0/address/year=2026/month=02\n",
      "[CONF] s0_partition_cols = ['region']\n"
     ]
    }
   ],
   "source": [
    "CONFIG_PATH = \"./config.yaml\"\n",
    "\n",
    "with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "ROOT = cfg[\"data_lake\"][\"root\"]\n",
    "LAYERS = cfg[\"data_lake\"][\"layers\"]\n",
    "\n",
    "# input\n",
    "address_clean_src_base = os.path.join(\n",
    "    ROOT,\n",
    "    LAYERS[\"silver\"][\"clean\"][\"domains\"][\"address_clean\"][\"paths\"][\"parquet\"]\n",
    ")\n",
    "address_clean_src_path = get_latest_year_month_path(spark, address_clean_src_base)\n",
    "\n",
    "coord_clean_src_base = os.path.join(\n",
    "    ROOT,\n",
    "    LAYERS[\"silver\"][\"clean\"][\"domains\"][\"coord_clean\"][\"paths\"][\"parquet\"]\n",
    ")\n",
    "coord_clean_src_path = get_latest_year_month_path(spark, coord_clean_src_base)\n",
    "\n",
    "\n",
    "# output\n",
    "s0_address_base = os.path.join(\n",
    "    ROOT,\n",
    "    LAYERS[\"silver\"][\"stages\"][\"s0\"][\"domains\"][\"address\"][\"paths\"][\"parquet\"]\n",
    ")\n",
    "s0_address_path = get_current_year_month_path(s0_address_base)\n",
    "\n",
    "s0_partition_cols = LAYERS[\"silver\"][\"stages\"][\"s0\"][\"domains\"][\"address\"].get(\"partition\")\n",
    "\n",
    "print(\"[PATH] address_src_path =\", address_clean_src_path)\n",
    "print(\"[PATH] coord_src_path   =\", coord_clean_src_path)\n",
    "print(\"[PATH] s0_address_path  =\", s0_address_path)\n",
    "print(\"[CONF] s0_partition_cols =\", s0_partition_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c482ae-794f-4a48-bb10-8f04062d00dd",
   "metadata": {},
   "source": [
    "# Bronze 데이터 로드 (도로명주소, 위치정보)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e5a2b8-dfce-43ad-8446-530e4c140ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PNU코드: string (nullable = true)\n",
      " |-- 도로명주소: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- 도로명주소: string (nullable = true)\n",
      " |-- x_utmk: double (nullable = true)\n",
      " |-- y_utmk: double (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LOAD\n",
    "# ============================================================\n",
    "addr_clean_df = spark.read.parquet(address_clean_src_path)\n",
    "coord_clean_df = spark.read.parquet(coord_clean_src_path)\n",
    "\n",
    "addr_clean_df.printSchema()\n",
    "coord_clean_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f59a65-5890-4798-b09e-9fb48df1c2ff",
   "metadata": {},
   "source": [
    "# 도로명주소, 위치정보 join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31249e72-92d0-4464-98e7-9421cf087023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined_df schema\n",
      "root\n",
      " |-- 도로명주소: string (nullable = true)\n",
      " |-- PNU코드: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- x_utmk: double (nullable = true)\n",
      " |-- y_utmk: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+-------------------+------+-------------+--------------+\n",
      "|도로명주소                              |PNU코드            |region|x_utmk       |y_utmk        |\n",
      "+----------------------------------------+-------------------+------+-------------+--------------+\n",
      "|경기도 수원시 장안구 경수대로 1022      |4111112900106270006|경기  |955711.416631|1923232.899067|\n",
      "|인천광역시 중구 신포로23번길 83         |2811010100100030001|인천  |922263.630299|1941913.515923|\n",
      "|전라남도 목포시 백년대로 48             |4611010100109570037|전남  |898887.779015|1645467.888812|\n",
      "|전라남도 목포시 백년대로 52             |4611010100111560017|전남  |898928.772203|1645472.306656|\n",
      "|전북특별자치도 전주시 완산구 충경로 18-7|5211110100100360006|전북  |967633.77642 |1757855.788657|\n",
      "+----------------------------------------+-------------------+------+-------------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joined_df = (\n",
    "    addr_clean_df\n",
    "    .join(coord_clean_df.drop(\"region\"), on=\"도로명주소\", how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"joined_df schema\")\n",
    "joined_df.printSchema()\n",
    "joined_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f2e46-fcd2-45d9-b3ad-89b909d4c86f",
   "metadata": {},
   "source": [
    "# 좌표 변환 (EPSG:5179 -> EPSG:4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eebd91c3-a155-4ada-afe0-ce28a2af5b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 도로명주소: string (nullable = true)\n",
      " |-- PNU코드: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- x_utmk: double (nullable = true)\n",
      " |-- y_utmk: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "@pandas_udf(schema)\n",
    "def utmk5179_to_wgs84(x: pd.Series, y: pd.Series) -> pd.DataFrame:\n",
    "    # ✅ executor에서 import + transformer 생성\n",
    "    from pyproj import Transformer\n",
    "    transformer = Transformer.from_crs(\"EPSG:5179\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "    # null 처리\n",
    "    mask = x.isna() | y.isna()\n",
    "    xx = x.astype(\"float64\")\n",
    "    yy = y.astype(\"float64\")\n",
    "\n",
    "    lon, lat = transformer.transform(xx, yy)\n",
    "\n",
    "    out = pd.DataFrame({\"latitude\": lat, \"longitude\": lon})\n",
    "    out.loc[mask, [\"latitude\", \"longitude\"]] = None\n",
    "    return out\n",
    "\n",
    "# 적용\n",
    "converted_df = (\n",
    "    joined_df\n",
    "    .withColumn(\"wgs84\", utmk5179_to_wgs84(F.col(\"x_utmk\"), F.col(\"y_utmk\")))\n",
    "    .withColumn(\"latitude\", F.col(\"wgs84.latitude\"))\n",
    "    .withColumn(\"longitude\", F.col(\"wgs84.longitude\"))\n",
    "    .drop(\"wgs84\")\n",
    ")\n",
    "\n",
    "converted_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fb28668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+----------------------------------------+------------------+------------------+\n",
      "|region|PNU코드            |도로명주소                              |longitude         |latitude          |\n",
      "+------+-------------------+----------------------------------------+------------------+------------------+\n",
      "|경기  |4111112900106270006|경기도 수원시 장안구 경수대로 1022      |127.0002267775931 |37.30700977864317 |\n",
      "|인천  |2811010100100030001|인천광역시 중구 신포로23번길 83         |126.62085396899394|37.47317831569107 |\n",
      "|전남  |4611010100109570037|전라남도 목포시 백년대로 48             |126.39466449475222|34.798756172106195|\n",
      "|전남  |4611010100111560017|전라남도 목포시 백년대로 52             |126.3951120175372 |34.79880007249072 |\n",
      "|전북  |5211110100100360006|전북특별자치도 전주시 완산구 충경로 18-7|127.14171282467188|35.81664114966993 |\n",
      "+------+-------------------+----------------------------------------+------------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joined_df = (\n",
    "    converted_df\n",
    "    .drop(\"x_utmk\", \"y_utmk\")\n",
    "    .select(\"region\", \"PNU코드\", \"도로명주소\", \"longitude\", \"latitude\")\n",
    ")\n",
    "\n",
    "joined_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d2b5f-8253-4a6d-960d-90a0b670d95a",
   "metadata": {},
   "source": [
    "# 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7e52868-39d2-477e-818b-827e192a6fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved: /opt/spark/data/silver/s0/address/year=2026/month=02\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    joined_df\n",
    "    .write.mode(\"overwrite\")\n",
    "    .partitionBy(*s0_partition_cols)\n",
    "    .parquet(s0_address_path)\n",
    ")\n",
    "\n",
    "print(\"✅ saved:\", s0_address_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88697a4a-79a9-47d8-a248-03301a4271a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
